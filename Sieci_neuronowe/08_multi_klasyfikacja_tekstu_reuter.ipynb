{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/reuters.npz\n",
      "2110848/2110848 [==============================] - 2s 1us/step\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.datasets import reuters\n",
    "\n",
    "(train_data, train_labels), (test_data, test_labels) = reuters.load_data(num_words = 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((8982,), (2246,))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape, test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([1,\n",
       "  3267,\n",
       "  699,\n",
       "  3434,\n",
       "  2295,\n",
       "  56,\n",
       "  2,\n",
       "  7511,\n",
       "  9,\n",
       "  56,\n",
       "  3906,\n",
       "  1073,\n",
       "  81,\n",
       "  5,\n",
       "  1198,\n",
       "  57,\n",
       "  366,\n",
       "  737,\n",
       "  132,\n",
       "  20,\n",
       "  4093,\n",
       "  7,\n",
       "  2,\n",
       "  49,\n",
       "  2295,\n",
       "  2,\n",
       "  1037,\n",
       "  3267,\n",
       "  699,\n",
       "  3434,\n",
       "  8,\n",
       "  7,\n",
       "  10,\n",
       "  241,\n",
       "  16,\n",
       "  855,\n",
       "  129,\n",
       "  231,\n",
       "  783,\n",
       "  5,\n",
       "  4,\n",
       "  587,\n",
       "  2295,\n",
       "  2,\n",
       "  2,\n",
       "  775,\n",
       "  7,\n",
       "  48,\n",
       "  34,\n",
       "  191,\n",
       "  44,\n",
       "  35,\n",
       "  1795,\n",
       "  505,\n",
       "  17,\n",
       "  12],\n",
       " 56)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[1], len(train_data[1]) #lista numerow indeksow słów"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([1,\n",
       "  2768,\n",
       "  283,\n",
       "  122,\n",
       "  7,\n",
       "  4,\n",
       "  89,\n",
       "  544,\n",
       "  463,\n",
       "  29,\n",
       "  798,\n",
       "  748,\n",
       "  40,\n",
       "  85,\n",
       "  306,\n",
       "  28,\n",
       "  19,\n",
       "  59,\n",
       "  11,\n",
       "  82,\n",
       "  84,\n",
       "  22,\n",
       "  10,\n",
       "  1315,\n",
       "  19,\n",
       "  12,\n",
       "  11,\n",
       "  82,\n",
       "  52,\n",
       "  29,\n",
       "  283,\n",
       "  1135,\n",
       "  558,\n",
       "  2,\n",
       "  265,\n",
       "  2,\n",
       "  6607,\n",
       "  8,\n",
       "  6607,\n",
       "  118,\n",
       "  371,\n",
       "  10,\n",
       "  1503,\n",
       "  281,\n",
       "  4,\n",
       "  143,\n",
       "  4811,\n",
       "  760,\n",
       "  50,\n",
       "  2088,\n",
       "  225,\n",
       "  139,\n",
       "  683,\n",
       "  4,\n",
       "  48,\n",
       "  193,\n",
       "  862,\n",
       "  41,\n",
       "  967,\n",
       "  1999,\n",
       "  30,\n",
       "  1086,\n",
       "  36,\n",
       "  8,\n",
       "  28,\n",
       "  602,\n",
       "  19,\n",
       "  32,\n",
       "  11,\n",
       "  82,\n",
       "  5,\n",
       "  4,\n",
       "  89,\n",
       "  544,\n",
       "  463,\n",
       "  41,\n",
       "  30,\n",
       "  6273,\n",
       "  13,\n",
       "  260,\n",
       "  951,\n",
       "  6607,\n",
       "  8,\n",
       "  69,\n",
       "  1749,\n",
       "  18,\n",
       "  82,\n",
       "  41,\n",
       "  30,\n",
       "  306,\n",
       "  3342,\n",
       "  13,\n",
       "  4,\n",
       "  37,\n",
       "  38,\n",
       "  283,\n",
       "  555,\n",
       "  649,\n",
       "  18,\n",
       "  82,\n",
       "  13,\n",
       "  1721,\n",
       "  282,\n",
       "  9,\n",
       "  132,\n",
       "  18,\n",
       "  82,\n",
       "  41,\n",
       "  30,\n",
       "  385,\n",
       "  21,\n",
       "  4,\n",
       "  169,\n",
       "  76,\n",
       "  36,\n",
       "  8,\n",
       "  107,\n",
       "  4,\n",
       "  106,\n",
       "  524,\n",
       "  10,\n",
       "  295,\n",
       "  3825,\n",
       "  2,\n",
       "  2476,\n",
       "  6,\n",
       "  3684,\n",
       "  6940,\n",
       "  4,\n",
       "  1126,\n",
       "  41,\n",
       "  263,\n",
       "  84,\n",
       "  395,\n",
       "  649,\n",
       "  18,\n",
       "  82,\n",
       "  838,\n",
       "  1317,\n",
       "  4,\n",
       "  572,\n",
       "  4,\n",
       "  106,\n",
       "  13,\n",
       "  25,\n",
       "  595,\n",
       "  2445,\n",
       "  40,\n",
       "  85,\n",
       "  7369,\n",
       "  518,\n",
       "  5,\n",
       "  4,\n",
       "  1126,\n",
       "  51,\n",
       "  115,\n",
       "  680,\n",
       "  16,\n",
       "  6,\n",
       "  719,\n",
       "  250,\n",
       "  27,\n",
       "  429,\n",
       "  6607,\n",
       "  8,\n",
       "  6940,\n",
       "  114,\n",
       "  343,\n",
       "  84,\n",
       "  142,\n",
       "  20,\n",
       "  5,\n",
       "  1145,\n",
       "  1538,\n",
       "  4,\n",
       "  65,\n",
       "  494,\n",
       "  474,\n",
       "  27,\n",
       "  69,\n",
       "  445,\n",
       "  11,\n",
       "  1816,\n",
       "  6607,\n",
       "  8,\n",
       "  109,\n",
       "  181,\n",
       "  2768,\n",
       "  2,\n",
       "  62,\n",
       "  1810,\n",
       "  6,\n",
       "  624,\n",
       "  901,\n",
       "  6940,\n",
       "  107,\n",
       "  4,\n",
       "  1126,\n",
       "  34,\n",
       "  524,\n",
       "  4,\n",
       "  6940,\n",
       "  1126,\n",
       "  41,\n",
       "  447,\n",
       "  7,\n",
       "  1427,\n",
       "  13,\n",
       "  69,\n",
       "  251,\n",
       "  18,\n",
       "  872,\n",
       "  876,\n",
       "  1539,\n",
       "  468,\n",
       "  9063,\n",
       "  242,\n",
       "  5,\n",
       "  646,\n",
       "  27,\n",
       "  1888,\n",
       "  169,\n",
       "  283,\n",
       "  87,\n",
       "  9,\n",
       "  10,\n",
       "  2,\n",
       "  260,\n",
       "  182,\n",
       "  122,\n",
       "  678,\n",
       "  306,\n",
       "  13,\n",
       "  4,\n",
       "  99,\n",
       "  216,\n",
       "  7,\n",
       "  89,\n",
       "  544,\n",
       "  64,\n",
       "  85,\n",
       "  2333,\n",
       "  6,\n",
       "  195,\n",
       "  7254,\n",
       "  6337,\n",
       "  268,\n",
       "  609,\n",
       "  4,\n",
       "  195,\n",
       "  41,\n",
       "  1017,\n",
       "  2765,\n",
       "  2,\n",
       "  4,\n",
       "  73,\n",
       "  706,\n",
       "  2,\n",
       "  92,\n",
       "  4,\n",
       "  91,\n",
       "  3917,\n",
       "  36,\n",
       "  8,\n",
       "  51,\n",
       "  144,\n",
       "  23,\n",
       "  1858,\n",
       "  129,\n",
       "  564,\n",
       "  13,\n",
       "  269,\n",
       "  678,\n",
       "  115,\n",
       "  55,\n",
       "  866,\n",
       "  189,\n",
       "  814,\n",
       "  604,\n",
       "  838,\n",
       "  117,\n",
       "  380,\n",
       "  595,\n",
       "  951,\n",
       "  320,\n",
       "  4,\n",
       "  398,\n",
       "  57,\n",
       "  2233,\n",
       "  7411,\n",
       "  269,\n",
       "  274,\n",
       "  87,\n",
       "  6607,\n",
       "  8,\n",
       "  787,\n",
       "  283,\n",
       "  34,\n",
       "  596,\n",
       "  661,\n",
       "  5467,\n",
       "  13,\n",
       "  2362,\n",
       "  1816,\n",
       "  90,\n",
       "  2,\n",
       "  84,\n",
       "  22,\n",
       "  2202,\n",
       "  1816,\n",
       "  54,\n",
       "  748,\n",
       "  6607,\n",
       "  8,\n",
       "  87,\n",
       "  62,\n",
       "  6154,\n",
       "  84,\n",
       "  161,\n",
       "  5,\n",
       "  1208,\n",
       "  480,\n",
       "  4,\n",
       "  2,\n",
       "  416,\n",
       "  6,\n",
       "  538,\n",
       "  122,\n",
       "  115,\n",
       "  55,\n",
       "  129,\n",
       "  1104,\n",
       "  1445,\n",
       "  345,\n",
       "  389,\n",
       "  31,\n",
       "  4,\n",
       "  169,\n",
       "  76,\n",
       "  36,\n",
       "  8,\n",
       "  787,\n",
       "  398,\n",
       "  7,\n",
       "  4,\n",
       "  2,\n",
       "  1507,\n",
       "  64,\n",
       "  8862,\n",
       "  22,\n",
       "  125,\n",
       "  2,\n",
       "  9,\n",
       "  2876,\n",
       "  172,\n",
       "  399,\n",
       "  9,\n",
       "  2,\n",
       "  5206,\n",
       "  9,\n",
       "  2,\n",
       "  122,\n",
       "  36,\n",
       "  8,\n",
       "  6642,\n",
       "  172,\n",
       "  247,\n",
       "  100,\n",
       "  97,\n",
       "  6940,\n",
       "  34,\n",
       "  75,\n",
       "  477,\n",
       "  541,\n",
       "  4,\n",
       "  283,\n",
       "  182,\n",
       "  4,\n",
       "  2,\n",
       "  295,\n",
       "  301,\n",
       "  2,\n",
       "  125,\n",
       "  2,\n",
       "  6607,\n",
       "  8,\n",
       "  77,\n",
       "  57,\n",
       "  445,\n",
       "  283,\n",
       "  1998,\n",
       "  217,\n",
       "  31,\n",
       "  380,\n",
       "  704,\n",
       "  51,\n",
       "  77,\n",
       "  2,\n",
       "  509,\n",
       "  5,\n",
       "  476,\n",
       "  9,\n",
       "  2876,\n",
       "  122,\n",
       "  115,\n",
       "  853,\n",
       "  6,\n",
       "  1061,\n",
       "  52,\n",
       "  10,\n",
       "  2,\n",
       "  2,\n",
       "  1308,\n",
       "  5,\n",
       "  4,\n",
       "  283,\n",
       "  182,\n",
       "  36,\n",
       "  8,\n",
       "  5296,\n",
       "  114,\n",
       "  30,\n",
       "  531,\n",
       "  6,\n",
       "  6376,\n",
       "  9,\n",
       "  2470,\n",
       "  529,\n",
       "  13,\n",
       "  2,\n",
       "  2,\n",
       "  58,\n",
       "  529,\n",
       "  7,\n",
       "  2148,\n",
       "  2,\n",
       "  185,\n",
       "  1028,\n",
       "  240,\n",
       "  5296,\n",
       "  1028,\n",
       "  949,\n",
       "  657,\n",
       "  57,\n",
       "  6,\n",
       "  1046,\n",
       "  283,\n",
       "  36,\n",
       "  8,\n",
       "  6607,\n",
       "  8,\n",
       "  4,\n",
       "  2217,\n",
       "  34,\n",
       "  9177,\n",
       "  13,\n",
       "  10,\n",
       "  4910,\n",
       "  5,\n",
       "  4,\n",
       "  141,\n",
       "  283,\n",
       "  120,\n",
       "  50,\n",
       "  2877,\n",
       "  7,\n",
       "  1049,\n",
       "  43,\n",
       "  10,\n",
       "  181,\n",
       "  283,\n",
       "  734,\n",
       "  115,\n",
       "  55,\n",
       "  3356,\n",
       "  476,\n",
       "  6,\n",
       "  2195,\n",
       "  10,\n",
       "  73,\n",
       "  120,\n",
       "  50,\n",
       "  41,\n",
       "  6877,\n",
       "  169,\n",
       "  87,\n",
       "  6607,\n",
       "  8,\n",
       "  107,\n",
       "  144,\n",
       "  23,\n",
       "  129,\n",
       "  120,\n",
       "  169,\n",
       "  87,\n",
       "  33,\n",
       "  2409,\n",
       "  30,\n",
       "  1888,\n",
       "  1171,\n",
       "  161,\n",
       "  4,\n",
       "  294,\n",
       "  517,\n",
       "  23,\n",
       "  2,\n",
       "  25,\n",
       "  398,\n",
       "  9,\n",
       "  2060,\n",
       "  283,\n",
       "  21,\n",
       "  4,\n",
       "  236,\n",
       "  36,\n",
       "  8,\n",
       "  143,\n",
       "  169,\n",
       "  87,\n",
       "  641,\n",
       "  1569,\n",
       "  28,\n",
       "  69,\n",
       "  61,\n",
       "  376,\n",
       "  514,\n",
       "  90,\n",
       "  1249,\n",
       "  62,\n",
       "  2,\n",
       "  13,\n",
       "  4,\n",
       "  2217,\n",
       "  696,\n",
       "  122,\n",
       "  404,\n",
       "  2936,\n",
       "  22,\n",
       "  134,\n",
       "  6,\n",
       "  187,\n",
       "  514,\n",
       "  10,\n",
       "  1249,\n",
       "  107,\n",
       "  4,\n",
       "  96,\n",
       "  1043,\n",
       "  1569,\n",
       "  13,\n",
       "  10,\n",
       "  184,\n",
       "  28,\n",
       "  61,\n",
       "  376,\n",
       "  514,\n",
       "  268,\n",
       "  680,\n",
       "  4,\n",
       "  320,\n",
       "  6,\n",
       "  154,\n",
       "  6,\n",
       "  69,\n",
       "  160,\n",
       "  514,\n",
       "  10,\n",
       "  1249,\n",
       "  27,\n",
       "  4,\n",
       "  153,\n",
       "  5,\n",
       "  52,\n",
       "  29,\n",
       "  36,\n",
       "  8,\n",
       "  6607,\n",
       "  8,\n",
       "  612,\n",
       "  408,\n",
       "  10,\n",
       "  3133,\n",
       "  283,\n",
       "  76,\n",
       "  27,\n",
       "  1504,\n",
       "  31,\n",
       "  169,\n",
       "  951,\n",
       "  2,\n",
       "  122,\n",
       "  36,\n",
       "  8,\n",
       "  283,\n",
       "  236,\n",
       "  62,\n",
       "  641,\n",
       "  84,\n",
       "  618,\n",
       "  2,\n",
       "  22,\n",
       "  8417,\n",
       "  8409,\n",
       "  9,\n",
       "  274,\n",
       "  7322,\n",
       "  399,\n",
       "  7587,\n",
       "  51,\n",
       "  115,\n",
       "  55,\n",
       "  45,\n",
       "  4044,\n",
       "  31,\n",
       "  4,\n",
       "  490,\n",
       "  558,\n",
       "  36,\n",
       "  8,\n",
       "  224,\n",
       "  2,\n",
       "  115,\n",
       "  57,\n",
       "  85,\n",
       "  1655,\n",
       "  2671,\n",
       "  5,\n",
       "  283,\n",
       "  6,\n",
       "  4,\n",
       "  37,\n",
       "  38,\n",
       "  7,\n",
       "  1797,\n",
       "  185,\n",
       "  77,\n",
       "  4446,\n",
       "  4,\n",
       "  555,\n",
       "  298,\n",
       "  77,\n",
       "  240,\n",
       "  2,\n",
       "  7,\n",
       "  327,\n",
       "  652,\n",
       "  194,\n",
       "  8773,\n",
       "  6233,\n",
       "  34,\n",
       "  2,\n",
       "  5463,\n",
       "  4884,\n",
       "  1297,\n",
       "  6,\n",
       "  240,\n",
       "  260,\n",
       "  458,\n",
       "  87,\n",
       "  6,\n",
       "  134,\n",
       "  514,\n",
       "  10,\n",
       "  1249,\n",
       "  22,\n",
       "  196,\n",
       "  514,\n",
       "  4,\n",
       "  37,\n",
       "  38,\n",
       "  309,\n",
       "  213,\n",
       "  54,\n",
       "  207,\n",
       "  8577,\n",
       "  25,\n",
       "  134,\n",
       "  139,\n",
       "  89,\n",
       "  283,\n",
       "  494,\n",
       "  555,\n",
       "  22,\n",
       "  4,\n",
       "  2217,\n",
       "  6,\n",
       "  2172,\n",
       "  4278,\n",
       "  434,\n",
       "  835,\n",
       "  22,\n",
       "  3598,\n",
       "  3746,\n",
       "  434,\n",
       "  835,\n",
       "  7,\n",
       "  48,\n",
       "  6607,\n",
       "  8,\n",
       "  618,\n",
       "  225,\n",
       "  586,\n",
       "  333,\n",
       "  122,\n",
       "  572,\n",
       "  126,\n",
       "  2768,\n",
       "  1998,\n",
       "  62,\n",
       "  133,\n",
       "  6,\n",
       "  2458,\n",
       "  233,\n",
       "  28,\n",
       "  602,\n",
       "  188,\n",
       "  5,\n",
       "  4,\n",
       "  704,\n",
       "  1998,\n",
       "  62,\n",
       "  45,\n",
       "  885,\n",
       "  281,\n",
       "  4,\n",
       "  48,\n",
       "  193,\n",
       "  760,\n",
       "  36,\n",
       "  8,\n",
       "  115,\n",
       "  680,\n",
       "  78,\n",
       "  58,\n",
       "  109,\n",
       "  95,\n",
       "  6,\n",
       "  1732,\n",
       "  1516,\n",
       "  281,\n",
       "  4,\n",
       "  225,\n",
       "  760,\n",
       "  17,\n",
       "  12],\n",
       " 745)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data[1], len(test_data[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 45)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels.min(), train_labels.max() # 46 roznych tematow "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_sequences(sequences, dimension=10000):\n",
    "    results = np.zeros((len(sequences), dimension))\n",
    "    for i, sequence in enumerate(sequences):\n",
    "        results[i, sequence] = 1.\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = vectorize_sequences(train_data)\n",
    "x_test = vectorize_sequences(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 1., ..., 0., 0., 0.],\n",
       "       [0., 1., 1., ..., 0., 0., 0.],\n",
       "       [0., 1., 1., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 1., 1., ..., 0., 0., 0.],\n",
       "       [0., 1., 1., ..., 0., 0., 0.],\n",
       "       [0., 1., 1., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_val = x_train[:1000]\n",
    "partial_x_train = x_train[1000:]\n",
    "\n",
    "y_val = train_labels[:1000]\n",
    "partial_y_train = train_labels[1000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "16/16 [==============================] - 2s 55ms/step - loss: 2.6187 - accuracy: 0.5220 - val_loss: 1.7282 - val_accuracy: 0.6460\n",
      "Epoch 2/20\n",
      "16/16 [==============================] - 1s 50ms/step - loss: 1.4068 - accuracy: 0.7057 - val_loss: 1.2909 - val_accuracy: 0.7200\n",
      "Epoch 3/20\n",
      "16/16 [==============================] - 1s 39ms/step - loss: 1.0409 - accuracy: 0.7800 - val_loss: 1.1445 - val_accuracy: 0.7470\n",
      "Epoch 4/20\n",
      "16/16 [==============================] - 0s 30ms/step - loss: 0.8137 - accuracy: 0.8254 - val_loss: 1.0365 - val_accuracy: 0.7720\n",
      "Epoch 5/20\n",
      "16/16 [==============================] - 1s 35ms/step - loss: 0.6483 - accuracy: 0.8643 - val_loss: 0.9929 - val_accuracy: 0.7880\n",
      "Epoch 6/20\n",
      "16/16 [==============================] - 1s 41ms/step - loss: 0.5149 - accuracy: 0.8904 - val_loss: 0.9318 - val_accuracy: 0.8000\n",
      "Epoch 7/20\n",
      "16/16 [==============================] - 1s 41ms/step - loss: 0.4170 - accuracy: 0.9104 - val_loss: 0.9077 - val_accuracy: 0.8090\n",
      "Epoch 8/20\n",
      "16/16 [==============================] - 1s 38ms/step - loss: 0.3378 - accuracy: 0.9276 - val_loss: 0.8913 - val_accuracy: 0.8230\n",
      "Epoch 9/20\n",
      "16/16 [==============================] - 1s 47ms/step - loss: 0.2819 - accuracy: 0.9380 - val_loss: 0.9192 - val_accuracy: 0.8080\n",
      "Epoch 10/20\n",
      "16/16 [==============================] - 1s 45ms/step - loss: 0.2379 - accuracy: 0.9469 - val_loss: 0.9099 - val_accuracy: 0.8150\n",
      "Epoch 11/20\n",
      "16/16 [==============================] - 1s 43ms/step - loss: 0.2028 - accuracy: 0.9498 - val_loss: 0.9471 - val_accuracy: 0.8070\n",
      "Epoch 12/20\n",
      "16/16 [==============================] - 1s 48ms/step - loss: 0.1812 - accuracy: 0.9530 - val_loss: 0.9993 - val_accuracy: 0.7990\n",
      "Epoch 13/20\n",
      "16/16 [==============================] - 1s 42ms/step - loss: 0.1647 - accuracy: 0.9545 - val_loss: 0.9518 - val_accuracy: 0.8210\n",
      "Epoch 14/20\n",
      "16/16 [==============================] - 0s 27ms/step - loss: 0.1499 - accuracy: 0.9558 - val_loss: 0.9678 - val_accuracy: 0.8090\n",
      "Epoch 15/20\n",
      "16/16 [==============================] - 0s 27ms/step - loss: 0.1384 - accuracy: 0.9545 - val_loss: 0.9955 - val_accuracy: 0.8090\n",
      "Epoch 16/20\n",
      "16/16 [==============================] - 0s 28ms/step - loss: 0.1293 - accuracy: 0.9588 - val_loss: 1.0184 - val_accuracy: 0.8090\n",
      "Epoch 17/20\n",
      "16/16 [==============================] - 1s 47ms/step - loss: 0.1270 - accuracy: 0.9560 - val_loss: 1.1636 - val_accuracy: 0.7780\n",
      "Epoch 18/20\n",
      "16/16 [==============================] - 1s 48ms/step - loss: 0.1211 - accuracy: 0.9567 - val_loss: 1.0508 - val_accuracy: 0.8080\n",
      "Epoch 19/20\n",
      "16/16 [==============================] - 1s 47ms/step - loss: 0.1129 - accuracy: 0.9585 - val_loss: 1.0495 - val_accuracy: 0.8040\n",
      "Epoch 20/20\n",
      "16/16 [==============================] - 1s 42ms/step - loss: 0.1160 - accuracy: 0.9583 - val_loss: 1.0922 - val_accuracy: 0.7960\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Dense(64, activation='relu', input_shape=(10000,)),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(46, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(loss='SparseCategoricalCrossentropy', optimizer=tf.keras.optimizers.RMSprop(), metrics='accuracy')\n",
    "\n",
    "history = model.fit(partial_x_train, partial_y_train, epochs = 20, batch_size = 512, validation_data = (x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.DataFrame(history.history).plot() #przeuczenie po 9 epoce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "16/16 [==============================] - 1s 41ms/step - loss: 2.5775 - accuracy: 0.5259 - val_loss: 1.6937 - val_accuracy: 0.6450\n",
      "Epoch 2/8\n",
      "16/16 [==============================] - 1s 34ms/step - loss: 1.4085 - accuracy: 0.6954 - val_loss: 1.3341 - val_accuracy: 0.7120\n",
      "Epoch 3/8\n",
      "16/16 [==============================] - 1s 34ms/step - loss: 1.0637 - accuracy: 0.7681 - val_loss: 1.1510 - val_accuracy: 0.7480\n",
      "Epoch 4/8\n",
      "16/16 [==============================] - 1s 31ms/step - loss: 0.8373 - accuracy: 0.8212 - val_loss: 1.0513 - val_accuracy: 0.7640\n",
      "Epoch 5/8\n",
      "16/16 [==============================] - 0s 28ms/step - loss: 0.6643 - accuracy: 0.8581 - val_loss: 0.9898 - val_accuracy: 0.7900\n",
      "Epoch 6/8\n",
      "16/16 [==============================] - 0s 28ms/step - loss: 0.5286 - accuracy: 0.8861 - val_loss: 0.9223 - val_accuracy: 0.8150\n",
      "Epoch 7/8\n",
      "16/16 [==============================] - 0s 28ms/step - loss: 0.4184 - accuracy: 0.9128 - val_loss: 0.9397 - val_accuracy: 0.8040\n",
      "Epoch 8/8\n",
      "16/16 [==============================] - 0s 31ms/step - loss: 0.3424 - accuracy: 0.9273 - val_loss: 0.9508 - val_accuracy: 0.8020\n"
     ]
    }
   ],
   "source": [
    "model2 = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Dense(64, activation='relu', input_shape=(10000,)),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(46, activation='softmax')\n",
    "])\n",
    "\n",
    "model2.compile(loss='SparseCategoricalCrossentropy', optimizer=tf.keras.optimizers.RMSprop(), metrics='accuracy')\n",
    "\n",
    "history2 = model2.fit(partial_x_train, partial_y_train, epochs = 8, batch_size = 512, validation_data = (x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.DataFrame(history2.history).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71/71 [==============================] - 0s 3ms/step - loss: 1.0063 - accuracy: 0.7792\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.006306767463684, 0.7791629433631897]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.evaluate(x_test, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6\n",
      "16/16 [==============================] - 2s 56ms/step - loss: 2.2626 - accuracy: 0.5443 - val_loss: 1.4638 - val_accuracy: 0.6790\n",
      "Epoch 2/6\n",
      "16/16 [==============================] - 1s 42ms/step - loss: 1.1961 - accuracy: 0.7321 - val_loss: 1.2243 - val_accuracy: 0.7180\n",
      "Epoch 3/6\n",
      "16/16 [==============================] - 1s 41ms/step - loss: 0.8637 - accuracy: 0.8007 - val_loss: 1.0283 - val_accuracy: 0.7670\n",
      "Epoch 4/6\n",
      "16/16 [==============================] - 1s 46ms/step - loss: 0.6284 - accuracy: 0.8564 - val_loss: 0.9620 - val_accuracy: 0.7960\n",
      "Epoch 5/6\n",
      "16/16 [==============================] - 1s 54ms/step - loss: 0.4578 - accuracy: 0.8933 - val_loss: 0.9255 - val_accuracy: 0.8220\n",
      "Epoch 6/6\n",
      "16/16 [==============================] - 1s 44ms/step - loss: 0.3414 - accuracy: 0.9240 - val_loss: 1.0962 - val_accuracy: 0.7730\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1dd2b837c40>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3 = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Dense(128, activation='relu', input_shape=(10000,)),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(46, activation='softmax')\n",
    "])\n",
    "\n",
    "model3.compile(loss='SparseCategoricalCrossentropy', optimizer=tf.keras.optimizers.RMSprop(), metrics='accuracy')\n",
    "\n",
    "model3.fit(partial_x_train, partial_y_train, epochs = 6, batch_size = 512, validation_data = (x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71/71 [==============================] - 0s 5ms/step - loss: 1.1964 - accuracy: 0.7422\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.1964004039764404, 0.7422083616256714]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3.evaluate(x_test, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/36\n",
      "16/16 [==============================] - 1s 53ms/step - loss: 3.3427 - accuracy: 0.4313 - val_loss: 2.9195 - val_accuracy: 0.5310\n",
      "Epoch 2/36\n",
      "16/16 [==============================] - 1s 40ms/step - loss: 2.6535 - accuracy: 0.5271 - val_loss: 2.4009 - val_accuracy: 0.5400\n",
      "Epoch 3/36\n",
      "16/16 [==============================] - 1s 45ms/step - loss: 2.2073 - accuracy: 0.5423 - val_loss: 2.0576 - val_accuracy: 0.5460\n",
      "Epoch 4/36\n",
      "16/16 [==============================] - 1s 45ms/step - loss: 1.9035 - accuracy: 0.5750 - val_loss: 1.8219 - val_accuracy: 0.5770\n",
      "Epoch 5/36\n",
      "16/16 [==============================] - 1s 44ms/step - loss: 1.6867 - accuracy: 0.6150 - val_loss: 1.6540 - val_accuracy: 0.6130\n",
      "Epoch 6/36\n",
      "16/16 [==============================] - 1s 45ms/step - loss: 1.5226 - accuracy: 0.6543 - val_loss: 1.5258 - val_accuracy: 0.6340\n",
      "Epoch 7/36\n",
      "16/16 [==============================] - 1s 42ms/step - loss: 1.3911 - accuracy: 0.6913 - val_loss: 1.4258 - val_accuracy: 0.6620\n",
      "Epoch 8/36\n",
      "16/16 [==============================] - 1s 39ms/step - loss: 1.2802 - accuracy: 0.7181 - val_loss: 1.3457 - val_accuracy: 0.6840\n",
      "Epoch 9/36\n",
      "16/16 [==============================] - 1s 43ms/step - loss: 1.1848 - accuracy: 0.7446 - val_loss: 1.2794 - val_accuracy: 0.7020\n",
      "Epoch 10/36\n",
      "16/16 [==============================] - 1s 45ms/step - loss: 1.1013 - accuracy: 0.7658 - val_loss: 1.2231 - val_accuracy: 0.7240\n",
      "Epoch 11/36\n",
      "16/16 [==============================] - 1s 48ms/step - loss: 1.0269 - accuracy: 0.7845 - val_loss: 1.1759 - val_accuracy: 0.7330\n",
      "Epoch 12/36\n",
      "16/16 [==============================] - 1s 56ms/step - loss: 0.9595 - accuracy: 0.8008 - val_loss: 1.1344 - val_accuracy: 0.7460\n",
      "Epoch 13/36\n",
      "16/16 [==============================] - 1s 56ms/step - loss: 0.8986 - accuracy: 0.8157 - val_loss: 1.0987 - val_accuracy: 0.7530\n",
      "Epoch 14/36\n",
      "16/16 [==============================] - 1s 55ms/step - loss: 0.8422 - accuracy: 0.8309 - val_loss: 1.0698 - val_accuracy: 0.7570\n",
      "Epoch 15/36\n",
      "16/16 [==============================] - 1s 56ms/step - loss: 0.7901 - accuracy: 0.8430 - val_loss: 1.0423 - val_accuracy: 0.7630\n",
      "Epoch 16/36\n",
      "16/16 [==============================] - 1s 54ms/step - loss: 0.7412 - accuracy: 0.8529 - val_loss: 1.0200 - val_accuracy: 0.7700\n",
      "Epoch 17/36\n",
      "16/16 [==============================] - 1s 56ms/step - loss: 0.6958 - accuracy: 0.8622 - val_loss: 0.9975 - val_accuracy: 0.7800\n",
      "Epoch 18/36\n",
      "16/16 [==============================] - 1s 54ms/step - loss: 0.6532 - accuracy: 0.8718 - val_loss: 0.9790 - val_accuracy: 0.7880\n",
      "Epoch 19/36\n",
      "16/16 [==============================] - 1s 55ms/step - loss: 0.6131 - accuracy: 0.8805 - val_loss: 0.9637 - val_accuracy: 0.7940\n",
      "Epoch 20/36\n",
      "16/16 [==============================] - 1s 59ms/step - loss: 0.5753 - accuracy: 0.8879 - val_loss: 0.9486 - val_accuracy: 0.7980\n",
      "Epoch 21/36\n",
      "16/16 [==============================] - 1s 53ms/step - loss: 0.5397 - accuracy: 0.8950 - val_loss: 0.9368 - val_accuracy: 0.8020\n",
      "Epoch 22/36\n",
      "16/16 [==============================] - 1s 42ms/step - loss: 0.5068 - accuracy: 0.9025 - val_loss: 0.9285 - val_accuracy: 0.7990\n",
      "Epoch 23/36\n",
      "16/16 [==============================] - 1s 61ms/step - loss: 0.4752 - accuracy: 0.9087 - val_loss: 0.9162 - val_accuracy: 0.8050\n",
      "Epoch 24/36\n",
      "16/16 [==============================] - 1s 53ms/step - loss: 0.4461 - accuracy: 0.9139 - val_loss: 0.9121 - val_accuracy: 0.8020\n",
      "Epoch 25/36\n",
      "16/16 [==============================] - 1s 40ms/step - loss: 0.4191 - accuracy: 0.9203 - val_loss: 0.9016 - val_accuracy: 0.8080\n",
      "Epoch 26/36\n",
      "16/16 [==============================] - 1s 45ms/step - loss: 0.3933 - accuracy: 0.9262 - val_loss: 0.8965 - val_accuracy: 0.8110\n",
      "Epoch 27/36\n",
      "16/16 [==============================] - 1s 51ms/step - loss: 0.3704 - accuracy: 0.9286 - val_loss: 0.8945 - val_accuracy: 0.8060\n",
      "Epoch 28/36\n",
      "16/16 [==============================] - 1s 55ms/step - loss: 0.3475 - accuracy: 0.9339 - val_loss: 0.8865 - val_accuracy: 0.8110\n",
      "Epoch 29/36\n",
      "16/16 [==============================] - 1s 51ms/step - loss: 0.3269 - accuracy: 0.9371 - val_loss: 0.8840 - val_accuracy: 0.8120\n",
      "Epoch 30/36\n",
      "16/16 [==============================] - 1s 41ms/step - loss: 0.3079 - accuracy: 0.9391 - val_loss: 0.8804 - val_accuracy: 0.8080\n",
      "Epoch 31/36\n",
      "16/16 [==============================] - 1s 40ms/step - loss: 0.2897 - accuracy: 0.9427 - val_loss: 0.8843 - val_accuracy: 0.8070\n",
      "Epoch 32/36\n",
      "16/16 [==============================] - 1s 41ms/step - loss: 0.2735 - accuracy: 0.9434 - val_loss: 0.8829 - val_accuracy: 0.8090\n",
      "Epoch 33/36\n",
      "16/16 [==============================] - 1s 41ms/step - loss: 0.2572 - accuracy: 0.9458 - val_loss: 0.8809 - val_accuracy: 0.8090\n",
      "Epoch 34/36\n",
      "16/16 [==============================] - 1s 42ms/step - loss: 0.2438 - accuracy: 0.9460 - val_loss: 0.8833 - val_accuracy: 0.8090\n",
      "Epoch 35/36\n",
      "16/16 [==============================] - 1s 44ms/step - loss: 0.2304 - accuracy: 0.9471 - val_loss: 0.8835 - val_accuracy: 0.8110\n",
      "Epoch 36/36\n",
      "16/16 [==============================] - 1s 50ms/step - loss: 0.2184 - accuracy: 0.9488 - val_loss: 0.8860 - val_accuracy: 0.8090\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1dd02fc33d0>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model4 = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Dense(128, activation='tanh', input_shape=(10000,)),\n",
    "    tf.keras.layers.Dense(128, activation='tanh'),\n",
    "    tf.keras.layers.Dense(128, activation='tanh'),\n",
    "    tf.keras.layers.Dense(46, activation='softmax')\n",
    "])\n",
    "\n",
    "model4.compile(loss='SparseCategoricalCrossentropy', optimizer=tf.keras.optimizers.RMSprop(learning_rate = 0.0001), metrics='accuracy')\n",
    "\n",
    "model4.fit(partial_x_train, partial_y_train, epochs = 36, batch_size = 512, validation_data = (x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71/71 [==============================] - 0s 5ms/step - loss: 1.0100 - accuracy: 0.7841\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.0099738836288452, 0.784060537815094]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model4.evaluate(x_test, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "16/16 [==============================] - 1s 50ms/step - loss: 3.6300 - accuracy: 0.2711 - val_loss: 3.3614 - val_accuracy: 0.5160\n",
      "Epoch 2/50\n",
      "16/16 [==============================] - 1s 42ms/step - loss: 3.1024 - accuracy: 0.5167 - val_loss: 2.8379 - val_accuracy: 0.5210\n",
      "Epoch 3/50\n",
      "16/16 [==============================] - 1s 34ms/step - loss: 2.5837 - accuracy: 0.5272 - val_loss: 2.3613 - val_accuracy: 0.5370\n",
      "Epoch 4/50\n",
      "16/16 [==============================] - 0s 31ms/step - loss: 2.1520 - accuracy: 0.5590 - val_loss: 2.0120 - val_accuracy: 0.5740\n",
      "Epoch 5/50\n",
      "16/16 [==============================] - 0s 31ms/step - loss: 1.8494 - accuracy: 0.6114 - val_loss: 1.7843 - val_accuracy: 0.6120\n",
      "Epoch 6/50\n",
      "16/16 [==============================] - 1s 36ms/step - loss: 1.6504 - accuracy: 0.6453 - val_loss: 1.6339 - val_accuracy: 0.6300\n",
      "Epoch 7/50\n",
      "16/16 [==============================] - 1s 33ms/step - loss: 1.5081 - accuracy: 0.6708 - val_loss: 1.5248 - val_accuracy: 0.6460\n",
      "Epoch 8/50\n",
      "16/16 [==============================] - 1s 31ms/step - loss: 1.3935 - accuracy: 0.6916 - val_loss: 1.4375 - val_accuracy: 0.6680\n",
      "Epoch 9/50\n",
      "16/16 [==============================] - 0s 31ms/step - loss: 1.2949 - accuracy: 0.7142 - val_loss: 1.3638 - val_accuracy: 0.6940\n",
      "Epoch 10/50\n",
      "16/16 [==============================] - 1s 34ms/step - loss: 1.2069 - accuracy: 0.7335 - val_loss: 1.3009 - val_accuracy: 0.7060\n",
      "Epoch 11/50\n",
      "16/16 [==============================] - 1s 39ms/step - loss: 1.1283 - accuracy: 0.7537 - val_loss: 1.2467 - val_accuracy: 0.7190\n",
      "Epoch 12/50\n",
      "16/16 [==============================] - 1s 45ms/step - loss: 1.0573 - accuracy: 0.7731 - val_loss: 1.2001 - val_accuracy: 0.7330\n",
      "Epoch 13/50\n",
      "16/16 [==============================] - 1s 44ms/step - loss: 0.9926 - accuracy: 0.7905 - val_loss: 1.1594 - val_accuracy: 0.7410\n",
      "Epoch 14/50\n",
      "16/16 [==============================] - 1s 32ms/step - loss: 0.9333 - accuracy: 0.8084 - val_loss: 1.1243 - val_accuracy: 0.7550\n",
      "Epoch 15/50\n",
      "16/16 [==============================] - 0s 31ms/step - loss: 0.8788 - accuracy: 0.8217 - val_loss: 1.0926 - val_accuracy: 0.7640\n",
      "Epoch 16/50\n",
      "16/16 [==============================] - 0s 31ms/step - loss: 0.8284 - accuracy: 0.8335 - val_loss: 1.0653 - val_accuracy: 0.7720\n",
      "Epoch 17/50\n",
      "16/16 [==============================] - 1s 34ms/step - loss: 0.7824 - accuracy: 0.8443 - val_loss: 1.0407 - val_accuracy: 0.7780\n",
      "Epoch 18/50\n",
      "16/16 [==============================] - 0s 30ms/step - loss: 0.7392 - accuracy: 0.8562 - val_loss: 1.0193 - val_accuracy: 0.7830\n",
      "Epoch 19/50\n",
      "16/16 [==============================] - 0s 31ms/step - loss: 0.6985 - accuracy: 0.8649 - val_loss: 0.9993 - val_accuracy: 0.7860\n",
      "Epoch 20/50\n",
      "16/16 [==============================] - 1s 35ms/step - loss: 0.6609 - accuracy: 0.8713 - val_loss: 0.9815 - val_accuracy: 0.7880\n",
      "Epoch 21/50\n",
      "16/16 [==============================] - 1s 33ms/step - loss: 0.6252 - accuracy: 0.8779 - val_loss: 0.9663 - val_accuracy: 0.7930\n",
      "Epoch 22/50\n",
      "16/16 [==============================] - 0s 30ms/step - loss: 0.5919 - accuracy: 0.8850 - val_loss: 0.9515 - val_accuracy: 0.8010\n",
      "Epoch 23/50\n",
      "16/16 [==============================] - 0s 31ms/step - loss: 0.5604 - accuracy: 0.8921 - val_loss: 0.9390 - val_accuracy: 0.8030\n",
      "Epoch 24/50\n",
      "16/16 [==============================] - 1s 34ms/step - loss: 0.5312 - accuracy: 0.8985 - val_loss: 0.9276 - val_accuracy: 0.8080\n",
      "Epoch 25/50\n",
      "16/16 [==============================] - 1s 36ms/step - loss: 0.5035 - accuracy: 0.9053 - val_loss: 0.9173 - val_accuracy: 0.8020\n",
      "Epoch 26/50\n",
      "16/16 [==============================] - 1s 35ms/step - loss: 0.4773 - accuracy: 0.9112 - val_loss: 0.9078 - val_accuracy: 0.8030\n",
      "Epoch 27/50\n",
      "16/16 [==============================] - 1s 34ms/step - loss: 0.4528 - accuracy: 0.9157 - val_loss: 0.8992 - val_accuracy: 0.8040\n",
      "Epoch 28/50\n",
      "16/16 [==============================] - 1s 36ms/step - loss: 0.4297 - accuracy: 0.9197 - val_loss: 0.8914 - val_accuracy: 0.8070\n",
      "Epoch 29/50\n",
      "16/16 [==============================] - 1s 32ms/step - loss: 0.4081 - accuracy: 0.9241 - val_loss: 0.8843 - val_accuracy: 0.8110\n",
      "Epoch 30/50\n",
      "16/16 [==============================] - 0s 31ms/step - loss: 0.3875 - accuracy: 0.9278 - val_loss: 0.8788 - val_accuracy: 0.8100\n",
      "Epoch 31/50\n",
      "16/16 [==============================] - 1s 33ms/step - loss: 0.3680 - accuracy: 0.9320 - val_loss: 0.8744 - val_accuracy: 0.8080\n",
      "Epoch 32/50\n",
      "16/16 [==============================] - 1s 32ms/step - loss: 0.3500 - accuracy: 0.9354 - val_loss: 0.8692 - val_accuracy: 0.8090\n",
      "Epoch 33/50\n",
      "16/16 [==============================] - 1s 33ms/step - loss: 0.3331 - accuracy: 0.9389 - val_loss: 0.8651 - val_accuracy: 0.8090\n",
      "Epoch 34/50\n",
      "16/16 [==============================] - 1s 33ms/step - loss: 0.3172 - accuracy: 0.9400 - val_loss: 0.8625 - val_accuracy: 0.8100\n",
      "Epoch 35/50\n",
      "16/16 [==============================] - 1s 34ms/step - loss: 0.3026 - accuracy: 0.9439 - val_loss: 0.8601 - val_accuracy: 0.8150\n",
      "Epoch 36/50\n",
      "16/16 [==============================] - 1s 33ms/step - loss: 0.2878 - accuracy: 0.9449 - val_loss: 0.8576 - val_accuracy: 0.8160\n",
      "Epoch 37/50\n",
      "16/16 [==============================] - 1s 32ms/step - loss: 0.2747 - accuracy: 0.9466 - val_loss: 0.8533 - val_accuracy: 0.8130\n",
      "Epoch 38/50\n",
      "16/16 [==============================] - 0s 31ms/step - loss: 0.2621 - accuracy: 0.9480 - val_loss: 0.8535 - val_accuracy: 0.8140\n",
      "Epoch 39/50\n",
      "16/16 [==============================] - 1s 34ms/step - loss: 0.2510 - accuracy: 0.9499 - val_loss: 0.8514 - val_accuracy: 0.8140\n",
      "Epoch 40/50\n",
      "16/16 [==============================] - 1s 32ms/step - loss: 0.2397 - accuracy: 0.9500 - val_loss: 0.8519 - val_accuracy: 0.8110\n",
      "Epoch 41/50\n",
      "16/16 [==============================] - 1s 32ms/step - loss: 0.2296 - accuracy: 0.9531 - val_loss: 0.8497 - val_accuracy: 0.8130\n",
      "Epoch 42/50\n",
      "16/16 [==============================] - 0s 31ms/step - loss: 0.2206 - accuracy: 0.9531 - val_loss: 0.8509 - val_accuracy: 0.8090\n",
      "Epoch 43/50\n",
      "16/16 [==============================] - 1s 31ms/step - loss: 0.2114 - accuracy: 0.9531 - val_loss: 0.8505 - val_accuracy: 0.8100\n",
      "Epoch 44/50\n",
      "16/16 [==============================] - 1s 32ms/step - loss: 0.2031 - accuracy: 0.9544 - val_loss: 0.8498 - val_accuracy: 0.8090\n",
      "Epoch 45/50\n",
      "16/16 [==============================] - 0s 31ms/step - loss: 0.1953 - accuracy: 0.9558 - val_loss: 0.8534 - val_accuracy: 0.8120\n",
      "Epoch 46/50\n",
      "16/16 [==============================] - 1s 32ms/step - loss: 0.1876 - accuracy: 0.9568 - val_loss: 0.8530 - val_accuracy: 0.8080\n",
      "Epoch 47/50\n",
      "16/16 [==============================] - 1s 32ms/step - loss: 0.1810 - accuracy: 0.9567 - val_loss: 0.8538 - val_accuracy: 0.8110\n",
      "Epoch 48/50\n",
      "16/16 [==============================] - 0s 31ms/step - loss: 0.1744 - accuracy: 0.9572 - val_loss: 0.8549 - val_accuracy: 0.8120\n",
      "Epoch 49/50\n",
      "16/16 [==============================] - 1s 33ms/step - loss: 0.1683 - accuracy: 0.9589 - val_loss: 0.8555 - val_accuracy: 0.8130\n",
      "Epoch 50/50\n",
      "16/16 [==============================] - 0s 31ms/step - loss: 0.1626 - accuracy: 0.9594 - val_loss: 0.8577 - val_accuracy: 0.8100\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1dd034d8ac0>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model5 = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Dense(128, activation='tanh', input_shape=(10000,)),\n",
    "    tf.keras.layers.Dense(128, activation='tanh'),\n",
    "    tf.keras.layers.Dense(128, activation='tanh'),\n",
    "    tf.keras.layers.Dense(46, activation='softmax')\n",
    "])\n",
    "\n",
    "model5.compile(loss='SparseCategoricalCrossentropy', optimizer=tf.keras.optimizers.Adam(learning_rate = 0.0001), metrics='accuracy')\n",
    "\n",
    "model5.fit(partial_x_train, partial_y_train, epochs = 50, batch_size = 512, validation_data = (x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71/71 [==============================] - 0s 3ms/step - loss: 0.9611 - accuracy: 0.7885\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.9610717296600342, 0.7885128855705261]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model5.evaluate(x_test, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "16/16 [==============================] - 1s 43ms/step - loss: 3.7779 - accuracy: 0.1267 - val_loss: 3.7154 - val_accuracy: 0.3690\n",
      "Epoch 2/50\n",
      "16/16 [==============================] - 1s 32ms/step - loss: 3.6398 - accuracy: 0.4412 - val_loss: 3.5289 - val_accuracy: 0.4650\n",
      "Epoch 3/50\n",
      "16/16 [==============================] - 1s 35ms/step - loss: 3.3892 - accuracy: 0.4803 - val_loss: 3.2059 - val_accuracy: 0.4960\n",
      "Epoch 4/50\n",
      "16/16 [==============================] - 1s 34ms/step - loss: 3.0150 - accuracy: 0.5063 - val_loss: 2.8079 - val_accuracy: 0.5170\n",
      "Epoch 5/50\n",
      "16/16 [==============================] - 1s 42ms/step - loss: 2.5992 - accuracy: 0.5289 - val_loss: 2.4068 - val_accuracy: 0.5300\n",
      "Epoch 6/50\n",
      "16/16 [==============================] - 1s 32ms/step - loss: 2.2009 - accuracy: 0.5454 - val_loss: 2.0594 - val_accuracy: 0.5540\n",
      "Epoch 7/50\n",
      "16/16 [==============================] - 0s 31ms/step - loss: 1.8872 - accuracy: 0.5933 - val_loss: 1.8220 - val_accuracy: 0.5930\n",
      "Epoch 8/50\n",
      "16/16 [==============================] - 0s 31ms/step - loss: 1.6682 - accuracy: 0.6505 - val_loss: 1.6604 - val_accuracy: 0.6400\n",
      "Epoch 9/50\n",
      "16/16 [==============================] - 1s 32ms/step - loss: 1.5089 - accuracy: 0.6862 - val_loss: 1.5465 - val_accuracy: 0.6670\n",
      "Epoch 10/50\n",
      "16/16 [==============================] - 1s 33ms/step - loss: 1.3870 - accuracy: 0.7056 - val_loss: 1.4594 - val_accuracy: 0.6760\n",
      "Epoch 11/50\n",
      "16/16 [==============================] - 1s 34ms/step - loss: 1.2871 - accuracy: 0.7204 - val_loss: 1.3922 - val_accuracy: 0.6900\n",
      "Epoch 12/50\n",
      "16/16 [==============================] - 1s 34ms/step - loss: 1.2011 - accuracy: 0.7353 - val_loss: 1.3375 - val_accuracy: 0.7070\n",
      "Epoch 13/50\n",
      "16/16 [==============================] - 1s 37ms/step - loss: 1.1230 - accuracy: 0.7552 - val_loss: 1.2887 - val_accuracy: 0.7210\n",
      "Epoch 14/50\n",
      "16/16 [==============================] - 1s 32ms/step - loss: 1.0519 - accuracy: 0.7755 - val_loss: 1.2506 - val_accuracy: 0.7340\n",
      "Epoch 15/50\n",
      "16/16 [==============================] - 1s 32ms/step - loss: 0.9870 - accuracy: 0.7944 - val_loss: 1.2124 - val_accuracy: 0.7430\n",
      "Epoch 16/50\n",
      "16/16 [==============================] - 1s 38ms/step - loss: 0.9261 - accuracy: 0.8076 - val_loss: 1.1827 - val_accuracy: 0.7480\n",
      "Epoch 17/50\n",
      "16/16 [==============================] - 1s 36ms/step - loss: 0.8696 - accuracy: 0.8193 - val_loss: 1.1540 - val_accuracy: 0.7530\n",
      "Epoch 18/50\n",
      "16/16 [==============================] - 1s 32ms/step - loss: 0.8152 - accuracy: 0.8314 - val_loss: 1.1265 - val_accuracy: 0.7620\n",
      "Epoch 19/50\n",
      "16/16 [==============================] - 1s 35ms/step - loss: 0.7659 - accuracy: 0.8418 - val_loss: 1.1023 - val_accuracy: 0.7680\n",
      "Epoch 20/50\n",
      "16/16 [==============================] - 1s 34ms/step - loss: 0.7196 - accuracy: 0.8489 - val_loss: 1.0856 - val_accuracy: 0.7730\n",
      "Epoch 21/50\n",
      "16/16 [==============================] - 1s 37ms/step - loss: 0.6760 - accuracy: 0.8601 - val_loss: 1.0618 - val_accuracy: 0.7800\n",
      "Epoch 22/50\n",
      "16/16 [==============================] - 0s 31ms/step - loss: 0.6348 - accuracy: 0.8688 - val_loss: 1.0448 - val_accuracy: 0.7770\n",
      "Epoch 23/50\n",
      "16/16 [==============================] - 0s 31ms/step - loss: 0.5967 - accuracy: 0.8761 - val_loss: 1.0328 - val_accuracy: 0.7820\n",
      "Epoch 24/50\n",
      "16/16 [==============================] - 1s 32ms/step - loss: 0.5603 - accuracy: 0.8820 - val_loss: 1.0144 - val_accuracy: 0.7850\n",
      "Epoch 25/50\n",
      "16/16 [==============================] - 1s 34ms/step - loss: 0.5269 - accuracy: 0.8890 - val_loss: 1.0044 - val_accuracy: 0.7870\n",
      "Epoch 26/50\n",
      "16/16 [==============================] - 1s 31ms/step - loss: 0.4946 - accuracy: 0.8965 - val_loss: 0.9957 - val_accuracy: 0.7930\n",
      "Epoch 27/50\n",
      "16/16 [==============================] - 1s 37ms/step - loss: 0.4644 - accuracy: 0.9037 - val_loss: 0.9835 - val_accuracy: 0.7940\n",
      "Epoch 28/50\n",
      "16/16 [==============================] - 1s 35ms/step - loss: 0.4368 - accuracy: 0.9112 - val_loss: 0.9786 - val_accuracy: 0.7990\n",
      "Epoch 29/50\n",
      "16/16 [==============================] - 1s 36ms/step - loss: 0.4110 - accuracy: 0.9193 - val_loss: 0.9698 - val_accuracy: 0.8040\n",
      "Epoch 30/50\n",
      "16/16 [==============================] - 0s 31ms/step - loss: 0.3870 - accuracy: 0.9228 - val_loss: 0.9676 - val_accuracy: 0.8070\n",
      "Epoch 31/50\n",
      "16/16 [==============================] - 1s 34ms/step - loss: 0.3655 - accuracy: 0.9286 - val_loss: 0.9585 - val_accuracy: 0.8030\n",
      "Epoch 32/50\n",
      "16/16 [==============================] - 1s 35ms/step - loss: 0.3443 - accuracy: 0.9313 - val_loss: 0.9579 - val_accuracy: 0.8100\n",
      "Epoch 33/50\n",
      "16/16 [==============================] - 1s 39ms/step - loss: 0.3239 - accuracy: 0.9346 - val_loss: 0.9533 - val_accuracy: 0.8060\n",
      "Epoch 34/50\n",
      "16/16 [==============================] - 1s 41ms/step - loss: 0.3060 - accuracy: 0.9371 - val_loss: 0.9523 - val_accuracy: 0.8080\n",
      "Epoch 35/50\n",
      "16/16 [==============================] - 1s 35ms/step - loss: 0.2898 - accuracy: 0.9384 - val_loss: 0.9478 - val_accuracy: 0.8060\n",
      "Epoch 36/50\n",
      "16/16 [==============================] - 1s 39ms/step - loss: 0.2745 - accuracy: 0.9404 - val_loss: 0.9489 - val_accuracy: 0.8100\n",
      "Epoch 37/50\n",
      "16/16 [==============================] - 0s 31ms/step - loss: 0.2601 - accuracy: 0.9434 - val_loss: 0.9469 - val_accuracy: 0.8050\n",
      "Epoch 38/50\n",
      "16/16 [==============================] - 1s 33ms/step - loss: 0.2471 - accuracy: 0.9449 - val_loss: 0.9520 - val_accuracy: 0.8080\n",
      "Epoch 39/50\n",
      "16/16 [==============================] - 1s 35ms/step - loss: 0.2343 - accuracy: 0.9464 - val_loss: 0.9509 - val_accuracy: 0.8110\n",
      "Epoch 40/50\n",
      "16/16 [==============================] - 1s 35ms/step - loss: 0.2230 - accuracy: 0.9478 - val_loss: 0.9486 - val_accuracy: 0.8090\n",
      "Epoch 41/50\n",
      "16/16 [==============================] - 1s 34ms/step - loss: 0.2138 - accuracy: 0.9491 - val_loss: 0.9510 - val_accuracy: 0.8130\n",
      "Epoch 42/50\n",
      "16/16 [==============================] - 1s 35ms/step - loss: 0.2047 - accuracy: 0.9495 - val_loss: 0.9575 - val_accuracy: 0.8100\n",
      "Epoch 43/50\n",
      "16/16 [==============================] - 1s 36ms/step - loss: 0.1951 - accuracy: 0.9533 - val_loss: 0.9532 - val_accuracy: 0.8110\n",
      "Epoch 44/50\n",
      "16/16 [==============================] - 1s 35ms/step - loss: 0.1860 - accuracy: 0.9529 - val_loss: 0.9573 - val_accuracy: 0.8100\n",
      "Epoch 45/50\n",
      "16/16 [==============================] - 1s 33ms/step - loss: 0.1788 - accuracy: 0.9545 - val_loss: 0.9622 - val_accuracy: 0.8130\n",
      "Epoch 46/50\n",
      "16/16 [==============================] - 1s 33ms/step - loss: 0.1717 - accuracy: 0.9559 - val_loss: 0.9596 - val_accuracy: 0.8090\n",
      "Epoch 47/50\n",
      "16/16 [==============================] - 1s 34ms/step - loss: 0.1646 - accuracy: 0.9550 - val_loss: 0.9682 - val_accuracy: 0.8110\n",
      "Epoch 48/50\n",
      "16/16 [==============================] - 1s 31ms/step - loss: 0.1580 - accuracy: 0.9569 - val_loss: 0.9693 - val_accuracy: 0.8080\n",
      "Epoch 49/50\n",
      "16/16 [==============================] - 1s 32ms/step - loss: 0.1531 - accuracy: 0.9569 - val_loss: 0.9764 - val_accuracy: 0.8120\n",
      "Epoch 50/50\n",
      "16/16 [==============================] - 1s 32ms/step - loss: 0.1480 - accuracy: 0.9580 - val_loss: 0.9783 - val_accuracy: 0.8080\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1dd036278e0>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model6 = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Dense(128, activation='relu', input_shape=(10000,)),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(46, activation='softmax')\n",
    "])\n",
    "\n",
    "model6.compile(loss='SparseCategoricalCrossentropy', optimizer=tf.keras.optimizers.Adam(learning_rate = 0.0001), metrics='accuracy')\n",
    "\n",
    "model6.fit(partial_x_train, partial_y_train, epochs = 50, batch_size = 512, validation_data = (x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71/71 [==============================] - 0s 4ms/step - loss: 1.0853 - accuracy: 0.7876\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.0853354930877686, 0.7876224517822266]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model6.evaluate(x_test, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6\n",
      "16/16 [==============================] - 1s 45ms/step - loss: 2.2957 - accuracy: 0.5029 - val_loss: 1.5099 - val_accuracy: 0.6480\n",
      "Epoch 2/6\n",
      "16/16 [==============================] - 1s 32ms/step - loss: 1.2372 - accuracy: 0.7185 - val_loss: 1.1239 - val_accuracy: 0.7380\n",
      "Epoch 3/6\n",
      "16/16 [==============================] - 1s 34ms/step - loss: 0.8312 - accuracy: 0.8210 - val_loss: 0.9458 - val_accuracy: 0.7980\n",
      "Epoch 4/6\n",
      "16/16 [==============================] - 1s 32ms/step - loss: 0.5510 - accuracy: 0.8911 - val_loss: 0.8577 - val_accuracy: 0.8090\n",
      "Epoch 5/6\n",
      "16/16 [==============================] - 1s 34ms/step - loss: 0.3665 - accuracy: 0.9302 - val_loss: 0.8299 - val_accuracy: 0.8180\n",
      "Epoch 6/6\n",
      "16/16 [==============================] - 1s 34ms/step - loss: 0.2542 - accuracy: 0.9459 - val_loss: 0.8264 - val_accuracy: 0.8250\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1dd2b7a15b0>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model7 = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Dense(128, activation='tanh', input_shape=(10000,)),\n",
    "    tf.keras.layers.Dense(128, activation='tanh'),\n",
    "    tf.keras.layers.Dense(128, activation='tanh'),\n",
    "    tf.keras.layers.Dense(46, activation='softmax')\n",
    "])\n",
    "\n",
    "model7.compile(loss='SparseCategoricalCrossentropy', optimizer=tf.keras.optimizers.Adam(learning_rate = 0.001), metrics='accuracy')\n",
    "\n",
    "model7.fit(partial_x_train, partial_y_train, epochs = 6, batch_size = 512, validation_data = (x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71/71 [==============================] - 0s 3ms/step - loss: 0.9205 - accuracy: 0.7983\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.9204806089401245, 0.7983080744743347]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model7.evaluate(x_test, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/33\n",
      "16/16 [==============================] - 2s 71ms/step - loss: 3.4914 - accuracy: 0.3826 - val_loss: 3.0761 - val_accuracy: 0.5300\n",
      "Epoch 2/33\n",
      "16/16 [==============================] - 1s 55ms/step - loss: 2.7420 - accuracy: 0.5363 - val_loss: 2.4197 - val_accuracy: 0.5430\n",
      "Epoch 3/33\n",
      "16/16 [==============================] - 1s 54ms/step - loss: 2.1515 - accuracy: 0.5728 - val_loss: 1.9722 - val_accuracy: 0.5810\n",
      "Epoch 4/33\n",
      "16/16 [==============================] - 1s 48ms/step - loss: 1.7774 - accuracy: 0.6320 - val_loss: 1.7187 - val_accuracy: 0.6200\n",
      "Epoch 5/33\n",
      "16/16 [==============================] - 1s 47ms/step - loss: 1.5534 - accuracy: 0.6670 - val_loss: 1.5581 - val_accuracy: 0.6440\n",
      "Epoch 6/33\n",
      "16/16 [==============================] - 1s 49ms/step - loss: 1.3967 - accuracy: 0.6982 - val_loss: 1.4426 - val_accuracy: 0.6660\n",
      "Epoch 7/33\n",
      "16/16 [==============================] - 1s 52ms/step - loss: 1.2725 - accuracy: 0.7260 - val_loss: 1.3530 - val_accuracy: 0.6810\n",
      "Epoch 8/33\n",
      "16/16 [==============================] - 1s 49ms/step - loss: 1.1671 - accuracy: 0.7512 - val_loss: 1.2800 - val_accuracy: 0.7080\n",
      "Epoch 9/33\n",
      "16/16 [==============================] - 1s 48ms/step - loss: 1.0762 - accuracy: 0.7727 - val_loss: 1.2199 - val_accuracy: 0.7340\n",
      "Epoch 10/33\n",
      "16/16 [==============================] - 1s 47ms/step - loss: 0.9948 - accuracy: 0.7934 - val_loss: 1.1683 - val_accuracy: 0.7520\n",
      "Epoch 11/33\n",
      "16/16 [==============================] - 1s 55ms/step - loss: 0.9216 - accuracy: 0.8102 - val_loss: 1.1254 - val_accuracy: 0.7620\n",
      "Epoch 12/33\n",
      "16/16 [==============================] - 1s 49ms/step - loss: 0.8551 - accuracy: 0.8270 - val_loss: 1.0887 - val_accuracy: 0.7720\n",
      "Epoch 13/33\n",
      "16/16 [==============================] - 1s 54ms/step - loss: 0.7942 - accuracy: 0.8411 - val_loss: 1.0559 - val_accuracy: 0.7830\n",
      "Epoch 14/33\n",
      "16/16 [==============================] - 1s 48ms/step - loss: 0.7381 - accuracy: 0.8515 - val_loss: 1.0271 - val_accuracy: 0.7880\n",
      "Epoch 15/33\n",
      "16/16 [==============================] - 1s 52ms/step - loss: 0.6870 - accuracy: 0.8639 - val_loss: 1.0028 - val_accuracy: 0.7900\n",
      "Epoch 16/33\n",
      "16/16 [==============================] - 1s 51ms/step - loss: 0.6399 - accuracy: 0.8753 - val_loss: 0.9789 - val_accuracy: 0.7980\n",
      "Epoch 17/33\n",
      "16/16 [==============================] - 1s 47ms/step - loss: 0.5959 - accuracy: 0.8831 - val_loss: 0.9595 - val_accuracy: 0.7990\n",
      "Epoch 18/33\n",
      "16/16 [==============================] - 1s 51ms/step - loss: 0.5551 - accuracy: 0.8914 - val_loss: 0.9416 - val_accuracy: 0.8000\n",
      "Epoch 19/33\n",
      "16/16 [==============================] - 1s 48ms/step - loss: 0.5177 - accuracy: 0.8993 - val_loss: 0.9256 - val_accuracy: 0.8070\n",
      "Epoch 20/33\n",
      "16/16 [==============================] - 1s 47ms/step - loss: 0.4833 - accuracy: 0.9077 - val_loss: 0.9109 - val_accuracy: 0.8100\n",
      "Epoch 21/33\n",
      "16/16 [==============================] - 1s 47ms/step - loss: 0.4514 - accuracy: 0.9134 - val_loss: 0.8981 - val_accuracy: 0.8110\n",
      "Epoch 22/33\n",
      "16/16 [==============================] - 1s 48ms/step - loss: 0.4218 - accuracy: 0.9204 - val_loss: 0.8880 - val_accuracy: 0.8140\n",
      "Epoch 23/33\n",
      "16/16 [==============================] - 1s 47ms/step - loss: 0.3948 - accuracy: 0.9252 - val_loss: 0.8777 - val_accuracy: 0.8190\n",
      "Epoch 24/33\n",
      "16/16 [==============================] - 1s 49ms/step - loss: 0.3701 - accuracy: 0.9297 - val_loss: 0.8702 - val_accuracy: 0.8170\n",
      "Epoch 25/33\n",
      "16/16 [==============================] - 1s 47ms/step - loss: 0.3470 - accuracy: 0.9347 - val_loss: 0.8634 - val_accuracy: 0.8180\n",
      "Epoch 26/33\n",
      "16/16 [==============================] - 1s 52ms/step - loss: 0.3260 - accuracy: 0.9370 - val_loss: 0.8579 - val_accuracy: 0.8170\n",
      "Epoch 27/33\n",
      "16/16 [==============================] - 1s 49ms/step - loss: 0.3066 - accuracy: 0.9387 - val_loss: 0.8531 - val_accuracy: 0.8220\n",
      "Epoch 28/33\n",
      "16/16 [==============================] - 1s 47ms/step - loss: 0.2890 - accuracy: 0.9426 - val_loss: 0.8487 - val_accuracy: 0.8230\n",
      "Epoch 29/33\n",
      "16/16 [==============================] - 1s 51ms/step - loss: 0.2719 - accuracy: 0.9459 - val_loss: 0.8461 - val_accuracy: 0.8230\n",
      "Epoch 30/33\n",
      "16/16 [==============================] - 1s 48ms/step - loss: 0.2573 - accuracy: 0.9466 - val_loss: 0.8442 - val_accuracy: 0.8240\n",
      "Epoch 31/33\n",
      "16/16 [==============================] - 1s 49ms/step - loss: 0.2431 - accuracy: 0.9493 - val_loss: 0.8422 - val_accuracy: 0.8210\n",
      "Epoch 32/33\n",
      "16/16 [==============================] - 1s 48ms/step - loss: 0.2305 - accuracy: 0.9494 - val_loss: 0.8425 - val_accuracy: 0.8220\n",
      "Epoch 33/33\n",
      "16/16 [==============================] - 1s 46ms/step - loss: 0.2190 - accuracy: 0.9511 - val_loss: 0.8411 - val_accuracy: 0.8220\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1dd6cdf9b50>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model8 = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Dense(256, activation='tanh', input_shape=(10000,)),\n",
    "    tf.keras.layers.Dense(256, activation='tanh'),\n",
    "    tf.keras.layers.Dense(46, activation='softmax')\n",
    "])\n",
    "\n",
    "model8.compile(loss='SparseCategoricalCrossentropy', optimizer=tf.keras.optimizers.Adam(learning_rate = 0.0001), metrics='accuracy')\n",
    "\n",
    "model8.fit(partial_x_train, partial_y_train, epochs = 33, batch_size = 512, validation_data = (x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71/71 [==============================] - 0s 6ms/step - loss: 0.9067 - accuracy: 0.7921\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.9067441821098328, 0.7920747995376587]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model8.evaluate(x_test, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/57\n",
      "16/16 [==============================] - 1s 43ms/step - loss: 3.5708 - accuracy: 0.2945 - val_loss: 3.3069 - val_accuracy: 0.4690\n",
      "Epoch 2/57\n",
      "16/16 [==============================] - 1s 33ms/step - loss: 3.1044 - accuracy: 0.4620 - val_loss: 2.8905 - val_accuracy: 0.4900\n",
      "Epoch 3/57\n",
      "16/16 [==============================] - 1s 33ms/step - loss: 2.6997 - accuracy: 0.4950 - val_loss: 2.5314 - val_accuracy: 0.5340\n",
      "Epoch 4/57\n",
      "16/16 [==============================] - 0s 31ms/step - loss: 2.3523 - accuracy: 0.5457 - val_loss: 2.2345 - val_accuracy: 0.5600\n",
      "Epoch 5/57\n",
      "16/16 [==============================] - 1s 32ms/step - loss: 2.0711 - accuracy: 0.5811 - val_loss: 2.0018 - val_accuracy: 0.5790\n",
      "Epoch 6/57\n",
      "16/16 [==============================] - 1s 35ms/step - loss: 1.8531 - accuracy: 0.6159 - val_loss: 1.8292 - val_accuracy: 0.6030\n",
      "Epoch 7/57\n",
      "16/16 [==============================] - 1s 34ms/step - loss: 1.6901 - accuracy: 0.6437 - val_loss: 1.7000 - val_accuracy: 0.6260\n",
      "Epoch 8/57\n",
      "16/16 [==============================] - 0s 30ms/step - loss: 1.5630 - accuracy: 0.6659 - val_loss: 1.5981 - val_accuracy: 0.6350\n",
      "Epoch 9/57\n",
      "16/16 [==============================] - 1s 32ms/step - loss: 1.4580 - accuracy: 0.6855 - val_loss: 1.5151 - val_accuracy: 0.6460\n",
      "Epoch 10/57\n",
      "16/16 [==============================] - 1s 33ms/step - loss: 1.3683 - accuracy: 0.7045 - val_loss: 1.4439 - val_accuracy: 0.6640\n",
      "Epoch 11/57\n",
      "16/16 [==============================] - 1s 32ms/step - loss: 1.2887 - accuracy: 0.7236 - val_loss: 1.3824 - val_accuracy: 0.6890\n",
      "Epoch 12/57\n",
      "16/16 [==============================] - 0s 30ms/step - loss: 1.2168 - accuracy: 0.7404 - val_loss: 1.3275 - val_accuracy: 0.7080\n",
      "Epoch 13/57\n",
      "16/16 [==============================] - 0s 31ms/step - loss: 1.1515 - accuracy: 0.7537 - val_loss: 1.2799 - val_accuracy: 0.7160\n",
      "Epoch 14/57\n",
      "16/16 [==============================] - 1s 34ms/step - loss: 1.0920 - accuracy: 0.7694 - val_loss: 1.2374 - val_accuracy: 0.7320\n",
      "Epoch 15/57\n",
      "16/16 [==============================] - 1s 33ms/step - loss: 1.0369 - accuracy: 0.7838 - val_loss: 1.1991 - val_accuracy: 0.7360\n",
      "Epoch 16/57\n",
      "16/16 [==============================] - 0s 31ms/step - loss: 0.9853 - accuracy: 0.7982 - val_loss: 1.1650 - val_accuracy: 0.7470\n",
      "Epoch 17/57\n",
      "16/16 [==============================] - 1s 32ms/step - loss: 0.9382 - accuracy: 0.8125 - val_loss: 1.1337 - val_accuracy: 0.7600\n",
      "Epoch 18/57\n",
      "16/16 [==============================] - 1s 35ms/step - loss: 0.8936 - accuracy: 0.8232 - val_loss: 1.1059 - val_accuracy: 0.7680\n",
      "Epoch 19/57\n",
      "16/16 [==============================] - 1s 34ms/step - loss: 0.8523 - accuracy: 0.8335 - val_loss: 1.0811 - val_accuracy: 0.7750\n",
      "Epoch 20/57\n",
      "16/16 [==============================] - 1s 33ms/step - loss: 0.8136 - accuracy: 0.8452 - val_loss: 1.0585 - val_accuracy: 0.7770\n",
      "Epoch 21/57\n",
      "16/16 [==============================] - 1s 34ms/step - loss: 0.7768 - accuracy: 0.8528 - val_loss: 1.0365 - val_accuracy: 0.7920\n",
      "Epoch 22/57\n",
      "16/16 [==============================] - 1s 34ms/step - loss: 0.7422 - accuracy: 0.8613 - val_loss: 1.0175 - val_accuracy: 0.7990\n",
      "Epoch 23/57\n",
      "16/16 [==============================] - 1s 31ms/step - loss: 0.7092 - accuracy: 0.8667 - val_loss: 0.9993 - val_accuracy: 0.8020\n",
      "Epoch 24/57\n",
      "16/16 [==============================] - 0s 30ms/step - loss: 0.6782 - accuracy: 0.8741 - val_loss: 0.9830 - val_accuracy: 0.8040\n",
      "Epoch 25/57\n",
      "16/16 [==============================] - 1s 34ms/step - loss: 0.6489 - accuracy: 0.8794 - val_loss: 0.9674 - val_accuracy: 0.8070\n",
      "Epoch 26/57\n",
      "16/16 [==============================] - 1s 33ms/step - loss: 0.6208 - accuracy: 0.8861 - val_loss: 0.9537 - val_accuracy: 0.8050\n",
      "Epoch 27/57\n",
      "16/16 [==============================] - 1s 32ms/step - loss: 0.5942 - accuracy: 0.8904 - val_loss: 0.9406 - val_accuracy: 0.8070\n",
      "Epoch 28/57\n",
      "16/16 [==============================] - 1s 33ms/step - loss: 0.5691 - accuracy: 0.8971 - val_loss: 0.9283 - val_accuracy: 0.8120\n",
      "Epoch 29/57\n",
      "16/16 [==============================] - 1s 34ms/step - loss: 0.5451 - accuracy: 0.9005 - val_loss: 0.9168 - val_accuracy: 0.8170\n",
      "Epoch 30/57\n",
      "16/16 [==============================] - 1s 32ms/step - loss: 0.5223 - accuracy: 0.9062 - val_loss: 0.9062 - val_accuracy: 0.8180\n",
      "Epoch 31/57\n",
      "16/16 [==============================] - 1s 32ms/step - loss: 0.5008 - accuracy: 0.9089 - val_loss: 0.8964 - val_accuracy: 0.8200\n",
      "Epoch 32/57\n",
      "16/16 [==============================] - 1s 33ms/step - loss: 0.4802 - accuracy: 0.9131 - val_loss: 0.8882 - val_accuracy: 0.8230\n",
      "Epoch 33/57\n",
      "16/16 [==============================] - 1s 33ms/step - loss: 0.4607 - accuracy: 0.9168 - val_loss: 0.8801 - val_accuracy: 0.8250\n",
      "Epoch 34/57\n",
      "16/16 [==============================] - 1s 33ms/step - loss: 0.4420 - accuracy: 0.9208 - val_loss: 0.8723 - val_accuracy: 0.8220\n",
      "Epoch 35/57\n",
      "16/16 [==============================] - 0s 31ms/step - loss: 0.4243 - accuracy: 0.9241 - val_loss: 0.8663 - val_accuracy: 0.8220\n",
      "Epoch 36/57\n",
      "16/16 [==============================] - 1s 34ms/step - loss: 0.4077 - accuracy: 0.9256 - val_loss: 0.8594 - val_accuracy: 0.8220\n",
      "Epoch 37/57\n",
      "16/16 [==============================] - 1s 35ms/step - loss: 0.3916 - accuracy: 0.9293 - val_loss: 0.8531 - val_accuracy: 0.8220\n",
      "Epoch 38/57\n",
      "16/16 [==============================] - 1s 34ms/step - loss: 0.3766 - accuracy: 0.9315 - val_loss: 0.8483 - val_accuracy: 0.8240\n",
      "Epoch 39/57\n",
      "16/16 [==============================] - 0s 31ms/step - loss: 0.3622 - accuracy: 0.9336 - val_loss: 0.8435 - val_accuracy: 0.8250\n",
      "Epoch 40/57\n",
      "16/16 [==============================] - 0s 31ms/step - loss: 0.3486 - accuracy: 0.9362 - val_loss: 0.8385 - val_accuracy: 0.8260\n",
      "Epoch 41/57\n",
      "16/16 [==============================] - 1s 33ms/step - loss: 0.3356 - accuracy: 0.9390 - val_loss: 0.8348 - val_accuracy: 0.8240\n",
      "Epoch 42/57\n",
      "16/16 [==============================] - 1s 33ms/step - loss: 0.3233 - accuracy: 0.9410 - val_loss: 0.8317 - val_accuracy: 0.8220\n",
      "Epoch 43/57\n",
      "16/16 [==============================] - 0s 31ms/step - loss: 0.3115 - accuracy: 0.9415 - val_loss: 0.8288 - val_accuracy: 0.8200\n",
      "Epoch 44/57\n",
      "16/16 [==============================] - 1s 35ms/step - loss: 0.3005 - accuracy: 0.9441 - val_loss: 0.8259 - val_accuracy: 0.8230\n",
      "Epoch 45/57\n",
      "16/16 [==============================] - 1s 33ms/step - loss: 0.2896 - accuracy: 0.9456 - val_loss: 0.8238 - val_accuracy: 0.8220\n",
      "Epoch 46/57\n",
      "16/16 [==============================] - 1s 32ms/step - loss: 0.2799 - accuracy: 0.9451 - val_loss: 0.8214 - val_accuracy: 0.8260\n",
      "Epoch 47/57\n",
      "16/16 [==============================] - 0s 31ms/step - loss: 0.2700 - accuracy: 0.9473 - val_loss: 0.8190 - val_accuracy: 0.8240\n",
      "Epoch 48/57\n",
      "16/16 [==============================] - 1s 35ms/step - loss: 0.2609 - accuracy: 0.9484 - val_loss: 0.8183 - val_accuracy: 0.8270\n",
      "Epoch 49/57\n",
      "16/16 [==============================] - 1s 33ms/step - loss: 0.2520 - accuracy: 0.9509 - val_loss: 0.8166 - val_accuracy: 0.8280\n",
      "Epoch 50/57\n",
      "16/16 [==============================] - 1s 32ms/step - loss: 0.2438 - accuracy: 0.9505 - val_loss: 0.8159 - val_accuracy: 0.8280\n",
      "Epoch 51/57\n",
      "16/16 [==============================] - 0s 30ms/step - loss: 0.2359 - accuracy: 0.9530 - val_loss: 0.8147 - val_accuracy: 0.8260\n",
      "Epoch 52/57\n",
      "16/16 [==============================] - 1s 32ms/step - loss: 0.2282 - accuracy: 0.9531 - val_loss: 0.8144 - val_accuracy: 0.8280\n",
      "Epoch 53/57\n",
      "16/16 [==============================] - 1s 33ms/step - loss: 0.2215 - accuracy: 0.9536 - val_loss: 0.8140 - val_accuracy: 0.8270\n",
      "Epoch 54/57\n",
      "16/16 [==============================] - 1s 33ms/step - loss: 0.2145 - accuracy: 0.9551 - val_loss: 0.8136 - val_accuracy: 0.8260\n",
      "Epoch 55/57\n",
      "16/16 [==============================] - 0s 30ms/step - loss: 0.2080 - accuracy: 0.9548 - val_loss: 0.8133 - val_accuracy: 0.8240\n",
      "Epoch 56/57\n",
      "16/16 [==============================] - 1s 33ms/step - loss: 0.2017 - accuracy: 0.9555 - val_loss: 0.8141 - val_accuracy: 0.8260\n",
      "Epoch 57/57\n",
      "16/16 [==============================] - 0s 31ms/step - loss: 0.1958 - accuracy: 0.9551 - val_loss: 0.8144 - val_accuracy: 0.8260\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1dd6cfb3d60>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model9 = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Dense(128, activation='tanh', input_shape=(10000,)),\n",
    "    tf.keras.layers.Dense(128, activation='tanh'),\n",
    "    tf.keras.layers.Dense(46, activation='softmax')\n",
    "])\n",
    "\n",
    "model9.compile(loss='SparseCategoricalCrossentropy', optimizer=tf.keras.optimizers.Adam(learning_rate = 0.0001), metrics='accuracy')\n",
    "\n",
    "model9.fit(partial_x_train, partial_y_train, epochs = 57, batch_size = 512, validation_data = (x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71/71 [==============================] - 0s 4ms/step - loss: 0.9094 - accuracy: 0.7903\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.9093919992446899, 0.7902938723564148]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model9.evaluate(x_test, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "16/16 [==============================] - 1s 26ms/step - loss: 3.6842 - accuracy: 0.2461 - val_loss: 3.4918 - val_accuracy: 0.4560\n",
      "Epoch 2/100\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 3.3510 - accuracy: 0.4892 - val_loss: 3.1970 - val_accuracy: 0.5080\n",
      "Epoch 3/100\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 3.0672 - accuracy: 0.5174 - val_loss: 2.9368 - val_accuracy: 0.5200\n",
      "Epoch 4/100\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 2.8131 - accuracy: 0.5284 - val_loss: 2.7047 - val_accuracy: 0.5300\n",
      "Epoch 5/100\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 2.5855 - accuracy: 0.5445 - val_loss: 2.4994 - val_accuracy: 0.5440\n",
      "Epoch 6/100\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 2.3852 - accuracy: 0.5621 - val_loss: 2.3222 - val_accuracy: 0.5580\n",
      "Epoch 7/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 2.2124 - accuracy: 0.5846 - val_loss: 2.1720 - val_accuracy: 0.5690\n",
      "Epoch 8/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 2.0662 - accuracy: 0.6026 - val_loss: 2.0466 - val_accuracy: 0.5880\n",
      "Epoch 9/100\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 1.9423 - accuracy: 0.6194 - val_loss: 1.9405 - val_accuracy: 0.6000\n",
      "Epoch 10/100\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 1.8361 - accuracy: 0.6346 - val_loss: 1.8503 - val_accuracy: 0.6120\n",
      "Epoch 11/100\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 1.7444 - accuracy: 0.6491 - val_loss: 1.7717 - val_accuracy: 0.6260\n",
      "Epoch 12/100\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 1.6624 - accuracy: 0.6620 - val_loss: 1.7037 - val_accuracy: 0.6330\n",
      "Epoch 13/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 1.5900 - accuracy: 0.6720 - val_loss: 1.6425 - val_accuracy: 0.6430\n",
      "Epoch 14/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 1.5244 - accuracy: 0.6815 - val_loss: 1.5884 - val_accuracy: 0.6500\n",
      "Epoch 15/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 1.4646 - accuracy: 0.6937 - val_loss: 1.5396 - val_accuracy: 0.6510\n",
      "Epoch 16/100\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 1.4096 - accuracy: 0.7045 - val_loss: 1.4954 - val_accuracy: 0.6620\n",
      "Epoch 17/100\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 1.3589 - accuracy: 0.7132 - val_loss: 1.4551 - val_accuracy: 0.6720\n",
      "Epoch 18/100\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 1.3122 - accuracy: 0.7235 - val_loss: 1.4181 - val_accuracy: 0.6830\n",
      "Epoch 19/100\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 1.2682 - accuracy: 0.7339 - val_loss: 1.3839 - val_accuracy: 0.6900\n",
      "Epoch 20/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 1.2269 - accuracy: 0.7427 - val_loss: 1.3528 - val_accuracy: 0.7020\n",
      "Epoch 21/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 1.1882 - accuracy: 0.7532 - val_loss: 1.3235 - val_accuracy: 0.7030\n",
      "Epoch 22/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 1.1515 - accuracy: 0.7630 - val_loss: 1.2967 - val_accuracy: 0.7130\n",
      "Epoch 23/100\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 1.1167 - accuracy: 0.7731 - val_loss: 1.2711 - val_accuracy: 0.7190\n",
      "Epoch 24/100\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 1.0837 - accuracy: 0.7811 - val_loss: 1.2473 - val_accuracy: 0.7250\n",
      "Epoch 25/100\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 1.0519 - accuracy: 0.7899 - val_loss: 1.2251 - val_accuracy: 0.7350\n",
      "Epoch 26/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 1.0219 - accuracy: 0.7988 - val_loss: 1.2041 - val_accuracy: 0.7430\n",
      "Epoch 27/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.9931 - accuracy: 0.8069 - val_loss: 1.1844 - val_accuracy: 0.7460\n",
      "Epoch 28/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.9653 - accuracy: 0.8142 - val_loss: 1.1659 - val_accuracy: 0.7480\n",
      "Epoch 29/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.9388 - accuracy: 0.8201 - val_loss: 1.1484 - val_accuracy: 0.7610\n",
      "Epoch 30/100\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.9132 - accuracy: 0.8286 - val_loss: 1.1317 - val_accuracy: 0.7690\n",
      "Epoch 31/100\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.8884 - accuracy: 0.8343 - val_loss: 1.1163 - val_accuracy: 0.7690\n",
      "Epoch 32/100\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.8647 - accuracy: 0.8420 - val_loss: 1.1014 - val_accuracy: 0.7730\n",
      "Epoch 33/100\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.8417 - accuracy: 0.8479 - val_loss: 1.0871 - val_accuracy: 0.7740\n",
      "Epoch 34/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.8195 - accuracy: 0.8525 - val_loss: 1.0736 - val_accuracy: 0.7730\n",
      "Epoch 35/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.7981 - accuracy: 0.8569 - val_loss: 1.0617 - val_accuracy: 0.7770\n",
      "Epoch 36/100\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.7772 - accuracy: 0.8612 - val_loss: 1.0493 - val_accuracy: 0.7790\n",
      "Epoch 37/100\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.7573 - accuracy: 0.8666 - val_loss: 1.0378 - val_accuracy: 0.7820\n",
      "Epoch 38/100\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.7378 - accuracy: 0.8698 - val_loss: 1.0270 - val_accuracy: 0.7850\n",
      "Epoch 39/100\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.7189 - accuracy: 0.8723 - val_loss: 1.0163 - val_accuracy: 0.7920\n",
      "Epoch 40/100\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.7006 - accuracy: 0.8772 - val_loss: 1.0070 - val_accuracy: 0.7940\n",
      "Epoch 41/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.6830 - accuracy: 0.8814 - val_loss: 0.9976 - val_accuracy: 0.7950\n",
      "Epoch 42/100\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.6658 - accuracy: 0.8859 - val_loss: 0.9885 - val_accuracy: 0.7950\n",
      "Epoch 43/100\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.6491 - accuracy: 0.8880 - val_loss: 0.9797 - val_accuracy: 0.8010\n",
      "Epoch 44/100\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.6332 - accuracy: 0.8914 - val_loss: 0.9716 - val_accuracy: 0.8000\n",
      "Epoch 45/100\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.6173 - accuracy: 0.8956 - val_loss: 0.9641 - val_accuracy: 0.8010\n",
      "Epoch 46/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.6022 - accuracy: 0.8985 - val_loss: 0.9563 - val_accuracy: 0.8020\n",
      "Epoch 47/100\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5874 - accuracy: 0.9007 - val_loss: 0.9494 - val_accuracy: 0.8040\n",
      "Epoch 48/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5732 - accuracy: 0.9035 - val_loss: 0.9425 - val_accuracy: 0.8060\n",
      "Epoch 49/100\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.5592 - accuracy: 0.9047 - val_loss: 0.9361 - val_accuracy: 0.8060\n",
      "Epoch 50/100\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5458 - accuracy: 0.9070 - val_loss: 0.9299 - val_accuracy: 0.8060\n",
      "Epoch 51/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5325 - accuracy: 0.9098 - val_loss: 0.9240 - val_accuracy: 0.8070\n",
      "Epoch 52/100\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5199 - accuracy: 0.9116 - val_loss: 0.9182 - val_accuracy: 0.8090\n",
      "Epoch 53/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.5075 - accuracy: 0.9138 - val_loss: 0.9131 - val_accuracy: 0.8100\n",
      "Epoch 54/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.4955 - accuracy: 0.9156 - val_loss: 0.9077 - val_accuracy: 0.8100\n",
      "Epoch 55/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.4838 - accuracy: 0.9173 - val_loss: 0.9026 - val_accuracy: 0.8110\n",
      "Epoch 56/100\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.4726 - accuracy: 0.9196 - val_loss: 0.8983 - val_accuracy: 0.8140\n",
      "Epoch 57/100\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.4615 - accuracy: 0.9209 - val_loss: 0.8937 - val_accuracy: 0.8140\n",
      "Epoch 58/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 19ms/step - loss: 0.4508 - accuracy: 0.9231 - val_loss: 0.8891 - val_accuracy: 0.8170\n",
      "Epoch 59/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.4406 - accuracy: 0.9251 - val_loss: 0.8851 - val_accuracy: 0.8190\n",
      "Epoch 60/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.4304 - accuracy: 0.9271 - val_loss: 0.8813 - val_accuracy: 0.8190\n",
      "Epoch 61/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.4206 - accuracy: 0.9295 - val_loss: 0.8781 - val_accuracy: 0.8180\n",
      "Epoch 62/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.4110 - accuracy: 0.9311 - val_loss: 0.8747 - val_accuracy: 0.8190\n",
      "Epoch 63/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.4020 - accuracy: 0.9322 - val_loss: 0.8713 - val_accuracy: 0.8180\n",
      "Epoch 64/100\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.3929 - accuracy: 0.9345 - val_loss: 0.8688 - val_accuracy: 0.8190\n",
      "Epoch 65/100\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.3841 - accuracy: 0.9362 - val_loss: 0.8658 - val_accuracy: 0.8200\n",
      "Epoch 66/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.3757 - accuracy: 0.9379 - val_loss: 0.8630 - val_accuracy: 0.8200\n",
      "Epoch 67/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.3673 - accuracy: 0.9387 - val_loss: 0.8606 - val_accuracy: 0.8200\n",
      "Epoch 68/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.3594 - accuracy: 0.9395 - val_loss: 0.8581 - val_accuracy: 0.8210\n",
      "Epoch 69/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.3515 - accuracy: 0.9411 - val_loss: 0.8558 - val_accuracy: 0.8200\n",
      "Epoch 70/100\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.3439 - accuracy: 0.9427 - val_loss: 0.8534 - val_accuracy: 0.8240\n",
      "Epoch 71/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.3365 - accuracy: 0.9440 - val_loss: 0.8513 - val_accuracy: 0.8240\n",
      "Epoch 72/100\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.3294 - accuracy: 0.9442 - val_loss: 0.8495 - val_accuracy: 0.8240\n",
      "Epoch 73/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.3224 - accuracy: 0.9448 - val_loss: 0.8484 - val_accuracy: 0.8240\n",
      "Epoch 74/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.3157 - accuracy: 0.9454 - val_loss: 0.8461 - val_accuracy: 0.8220\n",
      "Epoch 75/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.3091 - accuracy: 0.9463 - val_loss: 0.8450 - val_accuracy: 0.8210\n",
      "Epoch 76/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.3027 - accuracy: 0.9475 - val_loss: 0.8434 - val_accuracy: 0.8220\n",
      "Epoch 77/100\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.2964 - accuracy: 0.9486 - val_loss: 0.8424 - val_accuracy: 0.8200\n",
      "Epoch 78/100\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.2904 - accuracy: 0.9500 - val_loss: 0.8406 - val_accuracy: 0.8220\n",
      "Epoch 79/100\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.2845 - accuracy: 0.9500 - val_loss: 0.8394 - val_accuracy: 0.8210\n",
      "Epoch 80/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.2787 - accuracy: 0.9503 - val_loss: 0.8384 - val_accuracy: 0.8200\n",
      "Epoch 81/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.2731 - accuracy: 0.9499 - val_loss: 0.8378 - val_accuracy: 0.8210\n",
      "Epoch 82/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.2678 - accuracy: 0.9511 - val_loss: 0.8367 - val_accuracy: 0.8210\n",
      "Epoch 83/100\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.2625 - accuracy: 0.9516 - val_loss: 0.8358 - val_accuracy: 0.8220\n",
      "Epoch 84/100\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.2574 - accuracy: 0.9525 - val_loss: 0.8353 - val_accuracy: 0.8220\n",
      "Epoch 85/100\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.2524 - accuracy: 0.9533 - val_loss: 0.8345 - val_accuracy: 0.8210\n",
      "Epoch 86/100\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.2476 - accuracy: 0.9544 - val_loss: 0.8345 - val_accuracy: 0.8210\n",
      "Epoch 87/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.2429 - accuracy: 0.9543 - val_loss: 0.8339 - val_accuracy: 0.8220\n",
      "Epoch 88/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.2382 - accuracy: 0.9544 - val_loss: 0.8337 - val_accuracy: 0.8220\n",
      "Epoch 89/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.2338 - accuracy: 0.9557 - val_loss: 0.8330 - val_accuracy: 0.8210\n",
      "Epoch 90/100\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.2296 - accuracy: 0.9548 - val_loss: 0.8327 - val_accuracy: 0.8220\n",
      "Epoch 91/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.2254 - accuracy: 0.9559 - val_loss: 0.8332 - val_accuracy: 0.8220\n",
      "Epoch 92/100\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.2212 - accuracy: 0.9564 - val_loss: 0.8327 - val_accuracy: 0.8180\n",
      "Epoch 93/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.2173 - accuracy: 0.9574 - val_loss: 0.8328 - val_accuracy: 0.8200\n",
      "Epoch 94/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.2133 - accuracy: 0.9572 - val_loss: 0.8325 - val_accuracy: 0.8180\n",
      "Epoch 95/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.2095 - accuracy: 0.9578 - val_loss: 0.8328 - val_accuracy: 0.8180\n",
      "Epoch 96/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.2058 - accuracy: 0.9578 - val_loss: 0.8327 - val_accuracy: 0.8150\n",
      "Epoch 97/100\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.2021 - accuracy: 0.9580 - val_loss: 0.8331 - val_accuracy: 0.8140\n",
      "Epoch 98/100\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.1986 - accuracy: 0.9569 - val_loss: 0.8335 - val_accuracy: 0.8150\n",
      "Epoch 99/100\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.1952 - accuracy: 0.9589 - val_loss: 0.8333 - val_accuracy: 0.8160\n",
      "Epoch 100/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.1919 - accuracy: 0.9588 - val_loss: 0.8338 - val_accuracy: 0.8160\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1dd8dc084c0>"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model10 = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Dense(64, activation='tanh', input_shape=(10000,)),\n",
    "    tf.keras.layers.Dense(64, activation='tanh'),\n",
    "    tf.keras.layers.Dense(46, activation='softmax')\n",
    "])\n",
    "\n",
    "model10.compile(loss='SparseCategoricalCrossentropy', optimizer=tf.keras.optimizers.Adam(learning_rate = 0.0001), metrics='accuracy')\n",
    "\n",
    "model10.fit(partial_x_train, partial_y_train, epochs = 100, batch_size = 512, validation_data = (x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71/71 [==============================] - 0s 2ms/step - loss: 0.9191 - accuracy: 0.7885\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.9191417098045349, 0.7885128855705261]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model10.evaluate(x_test, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "16/16 [==============================] - 1s 30ms/step - loss: 3.1723 - accuracy: 0.3270 - val_loss: 2.6352 - val_accuracy: 0.3560\n",
      "Epoch 2/150\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 2.4389 - accuracy: 0.4126 - val_loss: 2.2490 - val_accuracy: 0.4880\n",
      "Epoch 3/150\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 2.1684 - accuracy: 0.5113 - val_loss: 2.0645 - val_accuracy: 0.5220\n",
      "Epoch 4/150\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 2.0162 - accuracy: 0.5185 - val_loss: 1.9468 - val_accuracy: 0.5260\n",
      "Epoch 5/150\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 1.9114 - accuracy: 0.5318 - val_loss: 1.8605 - val_accuracy: 0.5420\n",
      "Epoch 6/150\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.8300 - accuracy: 0.5536 - val_loss: 1.7902 - val_accuracy: 0.5600\n",
      "Epoch 7/150\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 1.7640 - accuracy: 0.5748 - val_loss: 1.7316 - val_accuracy: 0.5760\n",
      "Epoch 8/150\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.7085 - accuracy: 0.5968 - val_loss: 1.6835 - val_accuracy: 0.6060\n",
      "Epoch 9/150\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 1.6619 - accuracy: 0.6209 - val_loss: 1.6432 - val_accuracy: 0.6360\n",
      "Epoch 10/150\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 1.6224 - accuracy: 0.6431 - val_loss: 1.6087 - val_accuracy: 0.6470\n",
      "Epoch 11/150\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 1.5879 - accuracy: 0.6571 - val_loss: 1.5784 - val_accuracy: 0.6490\n",
      "Epoch 12/150\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.5571 - accuracy: 0.6640 - val_loss: 1.5509 - val_accuracy: 0.6640\n",
      "Epoch 13/150\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.5284 - accuracy: 0.6734 - val_loss: 1.5257 - val_accuracy: 0.6680\n",
      "Epoch 14/150\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.5018 - accuracy: 0.6815 - val_loss: 1.5026 - val_accuracy: 0.6680\n",
      "Epoch 15/150\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 1.4763 - accuracy: 0.6859 - val_loss: 1.4802 - val_accuracy: 0.6740\n",
      "Epoch 16/150\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 1.4514 - accuracy: 0.6911 - val_loss: 1.4585 - val_accuracy: 0.6760\n",
      "Epoch 17/150\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 1.4274 - accuracy: 0.6942 - val_loss: 1.4386 - val_accuracy: 0.6800\n",
      "Epoch 18/150\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 1.4040 - accuracy: 0.6993 - val_loss: 1.4186 - val_accuracy: 0.6810\n",
      "Epoch 19/150\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.3807 - accuracy: 0.7028 - val_loss: 1.3996 - val_accuracy: 0.6830\n",
      "Epoch 20/150\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 1.3585 - accuracy: 0.7062 - val_loss: 1.3808 - val_accuracy: 0.6820\n",
      "Epoch 21/150\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 1.3366 - accuracy: 0.7083 - val_loss: 1.3636 - val_accuracy: 0.6910\n",
      "Epoch 22/150\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.3156 - accuracy: 0.7115 - val_loss: 1.3466 - val_accuracy: 0.6930\n",
      "Epoch 23/150\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 1.2952 - accuracy: 0.7135 - val_loss: 1.3303 - val_accuracy: 0.6960\n",
      "Epoch 24/150\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 1.2762 - accuracy: 0.7164 - val_loss: 1.3151 - val_accuracy: 0.6960\n",
      "Epoch 25/150\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 1.2566 - accuracy: 0.7186 - val_loss: 1.3028 - val_accuracy: 0.7040\n",
      "Epoch 26/150\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 1.2387 - accuracy: 0.7233 - val_loss: 1.2860 - val_accuracy: 0.7010\n",
      "Epoch 27/150\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 1.2214 - accuracy: 0.7235 - val_loss: 1.2739 - val_accuracy: 0.7020\n",
      "Epoch 28/150\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.2045 - accuracy: 0.7286 - val_loss: 1.2611 - val_accuracy: 0.7060\n",
      "Epoch 29/150\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.1884 - accuracy: 0.7310 - val_loss: 1.2492 - val_accuracy: 0.7110\n",
      "Epoch 30/150\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.1730 - accuracy: 0.7355 - val_loss: 1.2379 - val_accuracy: 0.7110\n",
      "Epoch 31/150\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 1.1579 - accuracy: 0.7378 - val_loss: 1.2280 - val_accuracy: 0.7120\n",
      "Epoch 32/150\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 1.1434 - accuracy: 0.7423 - val_loss: 1.2169 - val_accuracy: 0.7140\n",
      "Epoch 33/150\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 1.1294 - accuracy: 0.7447 - val_loss: 1.2092 - val_accuracy: 0.7170\n",
      "Epoch 34/150\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.1159 - accuracy: 0.7469 - val_loss: 1.2007 - val_accuracy: 0.7230\n",
      "Epoch 35/150\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.1027 - accuracy: 0.7502 - val_loss: 1.1927 - val_accuracy: 0.7220\n",
      "Epoch 36/150\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 1.0899 - accuracy: 0.7556 - val_loss: 1.1816 - val_accuracy: 0.7240\n",
      "Epoch 37/150\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 1.0777 - accuracy: 0.7566 - val_loss: 1.1743 - val_accuracy: 0.7280\n",
      "Epoch 38/150\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 1.0653 - accuracy: 0.7626 - val_loss: 1.1667 - val_accuracy: 0.7330\n",
      "Epoch 39/150\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.0535 - accuracy: 0.7647 - val_loss: 1.1584 - val_accuracy: 0.7330\n",
      "Epoch 40/150\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.0420 - accuracy: 0.7691 - val_loss: 1.1519 - val_accuracy: 0.7360\n",
      "Epoch 41/150\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.0304 - accuracy: 0.7717 - val_loss: 1.1465 - val_accuracy: 0.7420\n",
      "Epoch 42/150\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 1.0196 - accuracy: 0.7754 - val_loss: 1.1389 - val_accuracy: 0.7390\n",
      "Epoch 43/150\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 1.0086 - accuracy: 0.7785 - val_loss: 1.1325 - val_accuracy: 0.7440\n",
      "Epoch 44/150\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.9979 - accuracy: 0.7808 - val_loss: 1.1258 - val_accuracy: 0.7480\n",
      "Epoch 45/150\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.9873 - accuracy: 0.7826 - val_loss: 1.1226 - val_accuracy: 0.7490\n",
      "Epoch 46/150\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.9770 - accuracy: 0.7869 - val_loss: 1.1134 - val_accuracy: 0.7480\n",
      "Epoch 47/150\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.9669 - accuracy: 0.7885 - val_loss: 1.1082 - val_accuracy: 0.7530\n",
      "Epoch 48/150\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.9566 - accuracy: 0.7917 - val_loss: 1.1046 - val_accuracy: 0.7540\n",
      "Epoch 49/150\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.9470 - accuracy: 0.7938 - val_loss: 1.0963 - val_accuracy: 0.7570\n",
      "Epoch 50/150\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 0.9369 - accuracy: 0.7962 - val_loss: 1.0918 - val_accuracy: 0.7630\n",
      "Epoch 51/150\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.9275 - accuracy: 0.7998 - val_loss: 1.0871 - val_accuracy: 0.7630\n",
      "Epoch 52/150\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.9178 - accuracy: 0.8016 - val_loss: 1.0830 - val_accuracy: 0.7640\n",
      "Epoch 53/150\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.9085 - accuracy: 0.8059 - val_loss: 1.0795 - val_accuracy: 0.7660\n",
      "Epoch 54/150\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.8992 - accuracy: 0.8074 - val_loss: 1.0726 - val_accuracy: 0.7660\n",
      "Epoch 55/150\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.8901 - accuracy: 0.8096 - val_loss: 1.0680 - val_accuracy: 0.7670\n",
      "Epoch 56/150\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.8810 - accuracy: 0.8106 - val_loss: 1.0631 - val_accuracy: 0.7690\n",
      "Epoch 57/150\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.8721 - accuracy: 0.8141 - val_loss: 1.0597 - val_accuracy: 0.7730\n",
      "Epoch 58/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 24ms/step - loss: 0.8634 - accuracy: 0.8163 - val_loss: 1.0555 - val_accuracy: 0.7720\n",
      "Epoch 59/150\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.8545 - accuracy: 0.8186 - val_loss: 1.0494 - val_accuracy: 0.7730\n",
      "Epoch 60/150\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.8461 - accuracy: 0.8203 - val_loss: 1.0463 - val_accuracy: 0.7730\n",
      "Epoch 61/150\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.8375 - accuracy: 0.8221 - val_loss: 1.0427 - val_accuracy: 0.7740\n",
      "Epoch 62/150\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 0.8291 - accuracy: 0.8241 - val_loss: 1.0396 - val_accuracy: 0.7730\n",
      "Epoch 63/150\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.8208 - accuracy: 0.8254 - val_loss: 1.0360 - val_accuracy: 0.7730\n",
      "Epoch 64/150\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.8128 - accuracy: 0.8270 - val_loss: 1.0315 - val_accuracy: 0.7720\n",
      "Epoch 65/150\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.8045 - accuracy: 0.8285 - val_loss: 1.0281 - val_accuracy: 0.7760\n",
      "Epoch 66/150\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.7965 - accuracy: 0.8307 - val_loss: 1.0249 - val_accuracy: 0.7770\n",
      "Epoch 67/150\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 0.7885 - accuracy: 0.8324 - val_loss: 1.0205 - val_accuracy: 0.7800\n",
      "Epoch 68/150\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.7805 - accuracy: 0.8340 - val_loss: 1.0183 - val_accuracy: 0.7790\n",
      "Epoch 69/150\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.7731 - accuracy: 0.8359 - val_loss: 1.0131 - val_accuracy: 0.7810\n",
      "Epoch 70/150\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.7653 - accuracy: 0.8371 - val_loss: 1.0107 - val_accuracy: 0.7790\n",
      "Epoch 71/150\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.7579 - accuracy: 0.8389 - val_loss: 1.0081 - val_accuracy: 0.7800\n",
      "Epoch 72/150\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 0.7506 - accuracy: 0.8406 - val_loss: 1.0053 - val_accuracy: 0.7800\n",
      "Epoch 73/150\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.7432 - accuracy: 0.8416 - val_loss: 1.0011 - val_accuracy: 0.7800\n",
      "Epoch 74/150\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.7360 - accuracy: 0.8428 - val_loss: 0.9981 - val_accuracy: 0.7800\n",
      "Epoch 75/150\n",
      "16/16 [==============================] - 0s 25ms/step - loss: 0.7283 - accuracy: 0.8434 - val_loss: 0.9963 - val_accuracy: 0.7820\n",
      "Epoch 76/150\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.7212 - accuracy: 0.8455 - val_loss: 0.9947 - val_accuracy: 0.7820\n",
      "Epoch 77/150\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.7144 - accuracy: 0.8465 - val_loss: 0.9930 - val_accuracy: 0.7830\n",
      "Epoch 78/150\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.7076 - accuracy: 0.8490 - val_loss: 0.9887 - val_accuracy: 0.7850\n",
      "Epoch 79/150\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.7006 - accuracy: 0.8490 - val_loss: 0.9849 - val_accuracy: 0.7860\n",
      "Epoch 80/150\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.6938 - accuracy: 0.8504 - val_loss: 0.9821 - val_accuracy: 0.7850\n",
      "Epoch 81/150\n",
      "16/16 [==============================] - 0s 25ms/step - loss: 0.6868 - accuracy: 0.8522 - val_loss: 0.9835 - val_accuracy: 0.7830\n",
      "Epoch 82/150\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.6802 - accuracy: 0.8539 - val_loss: 0.9808 - val_accuracy: 0.7860\n",
      "Epoch 83/150\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.6739 - accuracy: 0.8543 - val_loss: 0.9744 - val_accuracy: 0.7870\n",
      "Epoch 84/150\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.6674 - accuracy: 0.8562 - val_loss: 0.9742 - val_accuracy: 0.7890\n",
      "Epoch 85/150\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.6609 - accuracy: 0.8583 - val_loss: 0.9718 - val_accuracy: 0.7880\n",
      "Epoch 86/150\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.6546 - accuracy: 0.8587 - val_loss: 0.9689 - val_accuracy: 0.7900\n",
      "Epoch 87/150\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.6484 - accuracy: 0.8608 - val_loss: 0.9676 - val_accuracy: 0.7910\n",
      "Epoch 88/150\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.6423 - accuracy: 0.8606 - val_loss: 0.9682 - val_accuracy: 0.7890\n",
      "Epoch 89/150\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.6362 - accuracy: 0.8624 - val_loss: 0.9623 - val_accuracy: 0.7910\n",
      "Epoch 90/150\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.6303 - accuracy: 0.8632 - val_loss: 0.9608 - val_accuracy: 0.7920\n",
      "Epoch 91/150\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.6244 - accuracy: 0.8647 - val_loss: 0.9583 - val_accuracy: 0.7940\n",
      "Epoch 92/150\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.6183 - accuracy: 0.8653 - val_loss: 0.9577 - val_accuracy: 0.7970\n",
      "Epoch 93/150\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.6123 - accuracy: 0.8658 - val_loss: 0.9563 - val_accuracy: 0.7900\n",
      "Epoch 94/150\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.6066 - accuracy: 0.8672 - val_loss: 0.9545 - val_accuracy: 0.7940\n",
      "Epoch 95/150\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.6011 - accuracy: 0.8690 - val_loss: 0.9525 - val_accuracy: 0.7950\n",
      "Epoch 96/150\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.5956 - accuracy: 0.8705 - val_loss: 0.9515 - val_accuracy: 0.7930\n",
      "Epoch 97/150\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.5899 - accuracy: 0.8716 - val_loss: 0.9481 - val_accuracy: 0.7940\n",
      "Epoch 98/150\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.5844 - accuracy: 0.8715 - val_loss: 0.9476 - val_accuracy: 0.7920\n",
      "Epoch 99/150\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.5790 - accuracy: 0.8722 - val_loss: 0.9475 - val_accuracy: 0.7950\n",
      "Epoch 100/150\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 0.5738 - accuracy: 0.8737 - val_loss: 0.9444 - val_accuracy: 0.7930\n",
      "Epoch 101/150\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.5684 - accuracy: 0.8750 - val_loss: 0.9432 - val_accuracy: 0.7940\n",
      "Epoch 102/150\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.5632 - accuracy: 0.8757 - val_loss: 0.9449 - val_accuracy: 0.7950\n",
      "Epoch 103/150\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.5582 - accuracy: 0.8773 - val_loss: 0.9417 - val_accuracy: 0.7980\n",
      "Epoch 104/150\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.5530 - accuracy: 0.8794 - val_loss: 0.9401 - val_accuracy: 0.7970\n",
      "Epoch 105/150\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.5477 - accuracy: 0.8805 - val_loss: 0.9364 - val_accuracy: 0.8030\n",
      "Epoch 106/150\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.5429 - accuracy: 0.8821 - val_loss: 0.9393 - val_accuracy: 0.7970\n",
      "Epoch 107/150\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.5378 - accuracy: 0.8831 - val_loss: 0.9351 - val_accuracy: 0.7950\n",
      "Epoch 108/150\n",
      "16/16 [==============================] - 0s 25ms/step - loss: 0.5331 - accuracy: 0.8841 - val_loss: 0.9372 - val_accuracy: 0.7970\n",
      "Epoch 109/150\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.5283 - accuracy: 0.8855 - val_loss: 0.9346 - val_accuracy: 0.7980\n",
      "Epoch 110/150\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.5235 - accuracy: 0.8869 - val_loss: 0.9331 - val_accuracy: 0.7980\n",
      "Epoch 111/150\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.5188 - accuracy: 0.8880 - val_loss: 0.9323 - val_accuracy: 0.7980\n",
      "Epoch 112/150\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.5139 - accuracy: 0.8900 - val_loss: 0.9308 - val_accuracy: 0.7970\n",
      "Epoch 113/150\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.5095 - accuracy: 0.8904 - val_loss: 0.9285 - val_accuracy: 0.7950\n",
      "Epoch 114/150\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.5051 - accuracy: 0.8909 - val_loss: 0.9283 - val_accuracy: 0.7980\n",
      "Epoch 115/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 23ms/step - loss: 0.5005 - accuracy: 0.8913 - val_loss: 0.9288 - val_accuracy: 0.7980\n",
      "Epoch 116/150\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.4960 - accuracy: 0.8936 - val_loss: 0.9274 - val_accuracy: 0.7980\n",
      "Epoch 117/150\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.4917 - accuracy: 0.8934 - val_loss: 0.9296 - val_accuracy: 0.8000\n",
      "Epoch 118/150\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.4875 - accuracy: 0.8940 - val_loss: 0.9275 - val_accuracy: 0.7990\n",
      "Epoch 119/150\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.4831 - accuracy: 0.8955 - val_loss: 0.9246 - val_accuracy: 0.8000\n",
      "Epoch 120/150\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.4789 - accuracy: 0.8968 - val_loss: 0.9233 - val_accuracy: 0.8020\n",
      "Epoch 121/150\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.4748 - accuracy: 0.8978 - val_loss: 0.9225 - val_accuracy: 0.8010\n",
      "Epoch 122/150\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 0.4707 - accuracy: 0.8979 - val_loss: 0.9222 - val_accuracy: 0.7990\n",
      "Epoch 123/150\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.4668 - accuracy: 0.8985 - val_loss: 0.9242 - val_accuracy: 0.7980\n",
      "Epoch 124/150\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.4626 - accuracy: 0.9008 - val_loss: 0.9215 - val_accuracy: 0.8000\n",
      "Epoch 125/150\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.4587 - accuracy: 0.9022 - val_loss: 0.9198 - val_accuracy: 0.8010\n",
      "Epoch 126/150\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.4545 - accuracy: 0.9025 - val_loss: 0.9193 - val_accuracy: 0.7980\n",
      "Epoch 127/150\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 0.4504 - accuracy: 0.9032 - val_loss: 0.9194 - val_accuracy: 0.8030\n",
      "Epoch 128/150\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.4464 - accuracy: 0.9050 - val_loss: 0.9177 - val_accuracy: 0.8000\n",
      "Epoch 129/150\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.4431 - accuracy: 0.9042 - val_loss: 0.9174 - val_accuracy: 0.8020\n",
      "Epoch 130/150\n",
      "16/16 [==============================] - 0s 28ms/step - loss: 0.4392 - accuracy: 0.9045 - val_loss: 0.9178 - val_accuracy: 0.7990\n",
      "Epoch 131/150\n",
      "16/16 [==============================] - 0s 28ms/step - loss: 0.4354 - accuracy: 0.9059 - val_loss: 0.9194 - val_accuracy: 0.7970\n",
      "Epoch 132/150\n",
      "16/16 [==============================] - 0s 27ms/step - loss: 0.4319 - accuracy: 0.9057 - val_loss: 0.9169 - val_accuracy: 0.7970\n",
      "Epoch 133/150\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.4282 - accuracy: 0.9082 - val_loss: 0.9164 - val_accuracy: 0.8010\n",
      "Epoch 134/150\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.4247 - accuracy: 0.9082 - val_loss: 0.9169 - val_accuracy: 0.7970\n",
      "Epoch 135/150\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.4209 - accuracy: 0.9075 - val_loss: 0.9156 - val_accuracy: 0.8010\n",
      "Epoch 136/150\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.4176 - accuracy: 0.9100 - val_loss: 0.9134 - val_accuracy: 0.8010\n",
      "Epoch 137/150\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.4142 - accuracy: 0.9112 - val_loss: 0.9141 - val_accuracy: 0.8020\n",
      "Epoch 138/150\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.4108 - accuracy: 0.9113 - val_loss: 0.9141 - val_accuracy: 0.8010\n",
      "Epoch 139/150\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.4077 - accuracy: 0.9099 - val_loss: 0.9119 - val_accuracy: 0.8020\n",
      "Epoch 140/150\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.4042 - accuracy: 0.9128 - val_loss: 0.9133 - val_accuracy: 0.7990\n",
      "Epoch 141/150\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.4005 - accuracy: 0.9143 - val_loss: 0.9164 - val_accuracy: 0.7990\n",
      "Epoch 142/150\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.3976 - accuracy: 0.9153 - val_loss: 0.9161 - val_accuracy: 0.8000\n",
      "Epoch 143/150\n",
      "16/16 [==============================] - 0s 26ms/step - loss: 0.3942 - accuracy: 0.9149 - val_loss: 0.9109 - val_accuracy: 0.8000\n",
      "Epoch 144/150\n",
      "16/16 [==============================] - 0s 29ms/step - loss: 0.3911 - accuracy: 0.9166 - val_loss: 0.9100 - val_accuracy: 0.8010\n",
      "Epoch 145/150\n",
      "16/16 [==============================] - 0s 29ms/step - loss: 0.3879 - accuracy: 0.9154 - val_loss: 0.9116 - val_accuracy: 0.8010\n",
      "Epoch 146/150\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.3846 - accuracy: 0.9194 - val_loss: 0.9130 - val_accuracy: 0.7990\n",
      "Epoch 147/150\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.3819 - accuracy: 0.9172 - val_loss: 0.9095 - val_accuracy: 0.8010\n",
      "Epoch 148/150\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.3787 - accuracy: 0.9189 - val_loss: 0.9114 - val_accuracy: 0.8000\n",
      "Epoch 149/150\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.3755 - accuracy: 0.9197 - val_loss: 0.9107 - val_accuracy: 0.8010\n",
      "Epoch 150/150\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.3729 - accuracy: 0.9194 - val_loss: 0.9097 - val_accuracy: 0.8010\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1dd8dbb2430>"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#experimental model\n",
    "\n",
    "model_exp = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Dense(128, activation='softsign', input_shape=(10000,)),\n",
    "    tf.keras.layers.Dense(128, activation='softsign'),\n",
    "    tf.keras.layers.Dense(46, activation='softmax')\n",
    "])\n",
    "\n",
    "model_exp.compile(loss='SparseCategoricalCrossentropy', optimizer=tf.keras.optimizers.SGD(learning_rate = 0.05), metrics='accuracy')\n",
    "\n",
    "model_exp.fit(partial_x_train, partial_y_train, epochs = 150, batch_size = 512, validation_data = (x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71/71 [==============================] - 0s 2ms/step - loss: 0.9934 - accuracy: 0.7747\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.9933626651763916, 0.7747105956077576]"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_exp.evaluate(x_test, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
